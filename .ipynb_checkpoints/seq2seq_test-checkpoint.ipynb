{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.processor import Code_Intent_Pairs, sub_slotmap\n",
    "from seq2seq2.model import Seq2Seq\n",
    "from seq2seq2.data import get_train_loader, get_test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## training parameters\n",
    "    'batch_size' : 32,\n",
    "    'lr' : 1e-4,\n",
    "    'teacher_force_rate' : 0.85,\n",
    "    'max_epochs' : 20,\n",
    "    'lr_reduce' : True,\n",
    "    'lr_keep_rate' : 0.95,\n",
    "    \n",
    "    ## encoder architecture\n",
    "    'encoder_layers' : 2,\n",
    "    'encoder_embed_size' : 128,\n",
    "    'encoder_hidden_size' : 384,\n",
    "    'encoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## decoder architecture\n",
    "    'decoder_layers' : 2,\n",
    "    'decoder_embed_size' : 128,\n",
    "    'decoder_hidden_size' : 384,\n",
    "    'decoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## attn architecture\n",
    "    'attn_hidden_size' : 384,\n",
    "    \n",
    "    ## visualization\n",
    "    'print_every': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_intent_pair = Code_Intent_Pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vocab/'\n",
    "code_intent_pair.load_dict(path)\n",
    "special_symbols = code_intent_pair.get_special_symbols()\n",
    "word_size = code_intent_pair.get_word_size()\n",
    "code_size = code_intent_pair.get_code_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'processed_corpus/train.json'\n",
    "train_entries = code_intent_pair.load_entries(train_path)\n",
    "code_intent_pair.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = get_train_loader(train_entries, special_symbols, hyperP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'processed_corpus/test.json'\n",
    "test_entries = code_intent_pair.load_entries(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_loader(test_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(word_size, code_size, hyperP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperP['lr'])\n",
    "loss_f = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperP[] == True:\n",
    "lr_reduce_f = lambda epoch: 0.95 ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, loss_f, hyperP):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(trainloader):\n",
    "        logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "        loss = loss_f(logits, original_out_seq)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show stats\n",
    "        loss_sum += loss.item()\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        total_correct += (predictions == original_out_seq).sum()\n",
    "        size += len(original_out_seq)\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            print('Train: loss:{}\\tacc:{}'.format(loss_sum/print_every, float(total_correct)/size), end='\\r')\n",
    "            loss_sum = 0\n",
    "            total_correct = 0\n",
    "            size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, validloader, loss_f, hyperP):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(validloader):\n",
    "            logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "            loss = loss_f(logits, original_out_seq)\n",
    "\n",
    "            # show stats\n",
    "            loss_sum += loss.item()\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            total_correct += (predictions == original_out_seq).sum()\n",
    "            size += len(original_out_seq)\n",
    "\n",
    "    print('Valid: loss:{}\\tacc:{}'.format(loss_sum/len(validloader), float(total_correct)/size), end='\\r')\n",
    "    return float(total_correct)/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: loss:3.8352596092224123\tacc:0.16996908582364198\n",
      "model saved\n",
      "Valid: loss:3.4919337368011476\tacc:0.25917856617105844\n",
      "model saved\n",
      "Valid: loss:3.068763993581136\tacc:0.323038421904902163\n",
      "model saved\n",
      "Train: loss:3.1443928241729737\tacc:0.3034257748776509\r"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for e in range(20):\n",
    "    train(model, trainloader, optimizer, loss_f, hyperP)\n",
    "    acc = valid(model, trainloader, loss_f, hyperP)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        model.save()\n",
    "        print()\n",
    "        print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:send a signal `signal.SIGUSR1` to the current process\n",
      "predicted:\teach each each itemgetter itemgetter each each each each itemgetter itemgetter each each itemgetter 15 each itemgetter each each each each each dirnames 'name' each each each each each each each each 'utf-8' 'utf-8' each each each each each 'utf-8' each each itemgetter each each groupby itemgetter each each each\n",
      "ground_truth:\tos.kill(os.getpid(), signal.SIGUSR1)\n",
      "\n",
      "intent:decode a hex string '4a4b4c' to UTF-8.\n",
      "predicted:\teach each each each each each each p p each each 5 each each bool p each each each each 5 each each 5 each each each p each each p p each each p p each each each 5 each each each 5 each each dot each p each\n",
      "ground_truth:\tbytes.fromhex('4a4b4c').decode('utf-8')\n",
      "\n",
      "intent:check if all elements in list `myList` are identical\n",
      "predicted:\twith each genfromtxt with with with with with each each with with genfromtxt call call p tuple params with with pandas with each each chr args bool bool bool args bool each chr concatenate bool bool bool bool ix each each bool tuple with with with with now now chr\n",
      "ground_truth:\tall(x == myList[0] for x in myList)\n",
      "\n",
      "intent:format number of spaces between strings `Python`, `:` and `Very Good` to be `20`\n",
      "predicted:\t'string_escape' rfind 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' del 'string_escape' del del 'string_escape' 'string_escape' 'string_escape' find_element_by_id find_element_by_id 'string_escape' sort_values now rfind parse 'string_escape' 'string_escape' del 'string_escape' del 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' find_element_by_id 'string_escape' genfromtxt genfromtxt 'string_escape' del del 'string_escape'\n",
      "ground_truth:\tprint('%*s : %*s' % (20, 'Python', 20, 'Very Good'))\n",
      "\n",
      "intent:How to convert a string from CP-1251 to UTF-8?\n",
      "predicted:\teach 5 == 5 getcwd getcwd getcwd getcwd _ 5 dot dot 5 5 each ast ast ast == ast with with 5 5 dot getcwd 5 append hours 5 hours 5 Popen 5 append hours read_csv hours each dict stack 5 dot hours each 5 each getcwd getcwd getcwd\n",
      "ground_truth:\td.decode('cp1251').encode('utf8')\n",
      "\n",
      "intent:get rid of None values in dictionary `kwargs`\n",
      "predicted:\t5 ) ) ) tuple ) ) ) ) ) tuple ) tuple args each dict [ [ concatenate concatenate __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ 60 'w' 'w' dict 5 each 5 genfromtxt __init__ __init__ __init__ __init__ __init__ __init__ chr chr __init__\n",
      "ground_truth:\tres = {k: v for k, v in list(kwargs.items()) if v is not None}\n",
      "\n",
      "intent:get rid of None values in dictionary `kwargs`\n",
      "predicted:\t) __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tres = dict((k, v) for k, v in kwargs.items() if v is not None)\n",
      "\n",
      "intent:capture final output of a chain of system commands `ps -ef | grep something | wc -l`\n",
      "predicted:\t) ) __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tsubprocess.check_output('ps -ef | grep something | wc -l', shell=True)\n",
      "\n",
      "intent:concatenate a list of strings `['a', 'b', 'c']`\n",
      "predicted:\t5 5 max 5 5 max 5 5 5 5 5 Popen 5 5 POST Popen 5 5 5 5 with 5 itemgetter 5 5 5 itemgetter tuple 5 itemgetter 5 5 tuple max 5 5 tuple 5 5 tuple tuple tuple max driver tuple 5 5 5 5 itemgetter\n",
      "ground_truth:\t\"\"\"\"\"\".join(['a', 'b', 'c'])\n",
      "\n",
      "intent:find intersection data between series `s1` and series `s2`\n",
      "predicted:\tconcatenate concatenate concatenate concatenate concatenate concatenate __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack each unpack getcwd getcwd getcwd __init__ with with with with with with with with with with with with with with with with with now now with with with with with with with\n",
      "ground_truth:\tpd.Series(list(set(s1).intersection(set(s2))))\n",
      "\n",
      "intent:sending http headers to `client`\n",
      "predicted:\teach each each md5 next each md5 each 'ignore' 'ignore' 'ignore' each each 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' each 'ignore' 'ignore' each each each 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' each each each 'ignore' dict 'ignore' each 'ignore' 'ignore' 'ignore'\n",
      "ground_truth:\tclient.send('HTTP/1.0 200 OK\\r\\n')\n",
      "\n",
      "intent:Format a datetime string `when` to extract date only\n",
      "predicted:\twith with now now now 'string_escape' max next next next next now now dict dict dict dict dict dict dict with with with now now now now now dict dict dict dict dict dict dict dict with max max bool bool 5 5 next next next compile 'f' each 5\n",
      "ground_truth:\tthen = datetime.datetime.strptime(when, '%Y-%m-%d').date()\n",
      "\n",
      "intent:split a multi-line string `inputString` into separate strings\n",
      "predicted:\twith bin p with params with with with now now now now lst find_element_by_id dict lst lst lst lst lst lst lst params getcwd now getcwd getcwd getcwd args unpack tuple args cursor cursor ValueError args args reduce params reduce reduce itemgetter reduce bin bin reduce reduce bin bin lst\n",
      "ground_truth:\tinputString.split('\\n')\n",
      "\n",
      "intent:Split a multi-line string ` a \\n b \\r\\n c ` by new line character `\\n`\n",
      "predicted:\twith with with with with with with each 5 5 5 5 __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ getcwd getcwd __init__ __init__ startswith getcwd __init__ getcwd getcwd getcwd args with with with with with with with with each startswith startswith each r args each each ==\n",
      "ground_truth:\t' a \\n b \\r\\n c '.split('\\n')\n",
      "\n",
      "intent:concatenate elements of list `b` by a colon \":\"\n",
      "predicted:\t'ignore' 5 5 genfromtxt 5 5 5 gca 5 5 5 gca genfromtxt gca remove 5 5 5 5 5 5 Popen 5 5 5 __init__ gca genfromtxt gca 5 5 __init__ __init__ __init__ 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore'\n",
      "ground_truth:\t\"\"\":\"\"\".join(str(x) for x in b)\n",
      "\n",
      "intent:get the first object from a queryset in django model `Entry`\n",
      "predicted:\tread_csv ~ chr chr chr __init__ chr chr chr __init__ each 5 with each each pattern dirnames driver driver 5 5 5 5 5 remove remove 5 each 5 gca 5 5 ~ 'ignore' 'ignore' 'ignore' each __init__ ~ ~ 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' params 'ignore' 'ignore' 'ignore'\n",
      "ground_truth:\tEntry.objects.filter()[:1].get()\n",
      "\n",
      "intent:Calculate sum over all rows of 2D numpy array\n",
      "predicted:\t5 max args find_element_by_id [ max 5 find_element_by_id params 5 __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ getcwd __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ getcwd getcwd __init__\n",
      "ground_truth:\ta.sum(axis=1)\n",
      "\n",
      "intent:enable warnings using action 'always'\n",
      "predicted:\teach __init__ __init__ __init__ __init__ __init__ unpack unpack unpack hours hours hours hours hours hours unquote tuple args 0.1 stream each dict __init__ each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack hours hours hours hours each\n",
      "ground_truth:\twarnings.simplefilter('always')\n",
      "\n",
      "intent:concatenate items of list `l` with a space ' '\n",
      "predicted:\targs concatenate concatenate concatenate concatenate driver 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 5 gca gca random tuple gca _ tuple tuple startswith tuple args args concatenate find_element_by_id _ find_element_by_id _ soup tuple tuple tuple 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 5 gca 5 gca\n",
      "ground_truth:\tprint(' '.join(map(str, l)))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:run script 'hello.py' with argument 'htmlfilename.htm' on terminal using python executable\n",
      "predicted:\t__init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tsubprocess.call(['python.exe', 'hello.py', 'htmlfilename.htm'])\n",
      "\n",
      "intent:How can I parse a time string containing milliseconds in it with python?\n",
      "predicted:\teach [ each each 0.1 next unquote decode each chr chr genfromtxt 'string_escape' ) ) 0.1 each 0.1 0.1 chr chr 0.1 not __init__ chr __init__ not __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ getcwd __init__ each not chr 'ignore' each each each chr 15\n",
      "ground_truth:\ttime.strptime('30/03/09 16:31:32.123', '%d/%m/%y %H:%M:%S.%f')\n",
      "\n",
      "intent:convert a string `my_string` with dot and comma into a float number `my_float`\n",
      "predicted:\tunpack unpack 5 'utf-8' 'utf-8' 'utf-8' 'utf-8' each 'utf-8' each 'utf-8' 'utf-8' struct 'utf-8' with with 'utf-8' 'utf-8' with 'utf-8' each 'utf-8' 'utf-8' with with each each 'utf-8' 'utf-8' with each each 'utf-8' 'utf-8' struct params each dict 'utf-8' 'utf-8' struct 'utf-8' 'utf-8' 'utf-8' 'utf-8' 'utf-8' 'utf-8' 'utf-8' 'utf-8' 'utf-8'\n",
      "ground_truth:\tmy_float = float(my_string.replace(',', ''))\n",
      "\n",
      "intent:convert a string `123,456.908` with dot and comma into a floating number\n",
      "predicted:\tunpack unpack read_csv unpack unpack cursor cursor md5 unpack unpack unpack unpack unpack ValueError 5 5 5 unpack unpack unpack 5 5 unpack unpack unpack unpack unpack unpack read_csv unpack unpack unpack read_csv read_csv else product tuple unpack unpack unpack ValueError product unpack unpack unpack ValueError unpack 5 unpack unpack\n",
      "ground_truth:\tfloat('123,456.908'.replace(',', ''))\n",
      "\n",
      "intent:set pythonpath in python script.\n",
      "predicted:\teach __init__ __init__ \n",
      " \n",
      " \n",
      " \n",
      " __init__ \n",
      " __init__ each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ 60 __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tsys.path.append('/path/to/whatever')\n",
      "\n",
      "intent:split string 'Words, words, words.' using a regex '(\\\\W+)'\n",
      "predicted:\teach each each each each each dirnames driver driver p each each each each driver each each tuple pop pop pop pop pop tuple tuple pop pop bool tuple tuple cursor cursor cursor sort_values args find_element_by_id each chr each cursor cursor bool bool pop pop each each tuple tuple tuple\n",
      "ground_truth:\tre.split('(\\\\W+)', 'Words, words, words.')\n",
      "\n",
      "intent:open a file `Output.txt` in append mode\n",
      "predicted:\ttuple lst time tuple time BeautifulSoup tuple BeautifulSoup tuple BeautifulSoup pop pop bool bool 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' replace replace del del random ast find_element_by_id shell time tuple __init__ time tuple 'top' pattern pattern tuple dirnames 'd' time concatenate concatenate concatenate 'string_escape'\n",
      "ground_truth:\tfile = open('Output.txt', 'a')\n",
      "\n",
      "intent:download a file \"http://www.example.com/songs/mp3.mp3\" over HTTP and save to \"mp3.mp3\"\n",
      "predicted:\teach each 5 each each 5 'name' each 5 each each each  5 'f' each each each p getcwd 5 each environ each 5 chdir with find_element_by_id None each 5 each dot 5 5 each 5 each each dot each each each p p 5 each each 5 p\n",
      "ground_truth:\turllib.request.urlretrieve('http://www.example.com/songs/mp3.mp3', 'mp3.mp3')\n",
      "\n",
      "intent:download a file `url` over HTTP and save to `file_name`\n",
      "predicted:\teach each each p p p each each each each each with with with with with unicodedata with with with with with with with with with with with with with with with with with p each with with with with rfind with with with with with with with with with\n",
      "ground_truth:\tu = urllib.request.urlopen(url)\n",
      "f = open(file_name, 'wb')\n",
      "meta = u.info()\n",
      "file_size = int(meta.getheaders('Content-Length')[0])\n",
      "print(('Downloading: %s Bytes: %s' % (file_name, file_size)))\n",
      "file_size_dl = 0\n",
      "block_sz = 8192\n",
      "while True:\n",
      "    buffer = u.read(block_sz)\n",
      "    if (not buffer):\n",
      "        break\n",
      "    file_size_dl += len(buffer)\n",
      "    f.write(buffer)\n",
      "    status = ('%10d  [%3.2f%%]' % (file_size_dl, ((file_size_dl * 100.0) / file_size)))\n",
      "    status = (status + (chr(8) * (len(status) + 1)))\n",
      "    print(status, end=' ')\n",
      "f.close()\n",
      "\n",
      "intent:download a file 'http://www.example.com/' over HTTP\n",
      "predicted:\teach each dot 5 each each ast 'name' 'string_escape' 'string_escape' 'string_escape' 5 replace each 'string_escape' 5 each 5 each each 5 5 'string_escape' each each getcwd 'string_escape' 'string_escape' each 5 'string_escape' replace replace each each tuple 'string_escape' 5 each with with with with with with with with with with now\n",
      "ground_truth:\tresponse = urllib.request.urlopen('http://www.example.com/')\n",
      "html = response.read()\n",
      "\n",
      "intent:download a file `url` over HTTP\n",
      "predicted:\tread_csv 15 15 with with with with with with with with with with with with with rfind tuple with with with with with with with with with with with with with with with with with with with with with with with with rfind call call 5 5 find_element_by_id find_element_by_id chr\n",
      "ground_truth:\tr = requests.get(url)\n",
      "\n",
      "intent:download a file `url` over HTTP and save to \"10MB\"\n",
      "predicted:\teach each with with with with with each with each with with with with with each with with with with with with with with with now find_element_by_id with with with each with with with each with with with each with find_element_by_id find_element_by_id find_element_by_id params unpack unpack unpack unpack unpack unpack\n",
      "ground_truth:\tresponse = requests.get(url, stream=True)\n",
      "with open('10MB', 'wb') as handle:\n",
      "    for data in tqdm(response.iter_content()):\n",
      "        handle.write(data)\n",
      "\n",
      "intent:argparse add argument with flag '--version' and version action of '%(prog)s 2.0' to parser `parser`\n",
      "predicted:\t__init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack unpack hours hours hours hours not __init__ each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tparser.add_argument('--version', action='version', version='%(prog)s 2.0')\n",
      "\n",
      "intent:remove key 'c' from dictionary `d`\n",
      "predicted:\teach   eval lst each finditer finditer each finditer each finditer dict dict dict hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest hexdigest each hexdigest hexdigest 5 each finditer finditer finditer each finditer hexdigest hexdigest dict hexdigest each dirnames 'name' concatenate ~ ~ ~\n",
      "ground_truth:\t{i: d[i] for i in d if i != 'c'}\n",
      "\n",
      "intent:Create new DataFrame object by merging columns \"key\" of  dataframes `split_df` and `csv_df` and rename the columns from dataframes `split_df` and `csv_df` with suffix `_left` and `_right` respectively\n",
      "predicted:\t5 __init__ unpack unpack unpack 5 unpack unpack 5 0.1 concatenate unpack unpack 5 5 unpack unpack unpack 5 5 5 __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack unpack unpack 5 5 unpack unpack unpack 5\n",
      "ground_truth:\tpd.merge(split_df, csv_df, on=['key'], suffixes=('_left', '_right'))\n",
      "\n",
      "intent:Split a string `s` by space with `4` splits\n",
      "predicted:\tcursor params params conn conn params p p dict tuple args params dict dict dict dict dict dict dict chr chr rfind tuple reduce text reduce text item tuple params item tuple tuple pattern pattern cursor cursor chr chr find_element_by_id params chr chr chr 7 tuple itemgetter tuple cursor text\n",
      "ground_truth:\ts.split(' ', 4)\n",
      "\n",
      "intent:read keyboard-input\n",
      "predicted:\tunpack unpack unpack unpack unpack max concatenate max max ValueError ValueError max max max True max max max max max max max max max max max max max max max ValueError max ValueError True True unpack max max max ValueError ValueError True unpack unpack max ValueError max max max max\n",
      "ground_truth:\tinput('Enter your input:')\n",
      "\n",
      "intent:enable debug mode on Flask application `app`\n",
      "predicted:\t__init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tapp.run(debug=True)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:python save list `mylist` to file object 'save.txt'\n",
      "predicted:\tnext each bool next next now now now next next now now now next next str_2 str_2 str_2 max 5 5 stack 5 next arange arange filenames tuple arange arange filenames arange max getcwd now now now str_2 now ~ ~ ~ now chr shell tuple args args max max\n",
      "ground_truth:\tpickle.dump(mylist, open('save.txt', 'wb'))\n",
      "\n",
      "intent:Multiply a matrix `P` with a 3d tensor `T` in scipy\n",
      "predicted:\teach __init__ each each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ each __init__ __init__ __init__ __init__ __init__ each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__\n",
      "ground_truth:\tscipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)\n",
      "\n",
      "intent:Create 3d array of zeroes of size `(3,3,3)`\n",
      "predicted:\teach each __init__ __init__ __init__ __init__ unpack dict unpack unpack 5 5 5 zip zip __init__ zip unpack unpack unpack 5 5 5 5 unpack __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack each getcwd getcwd dict dict stack stack dict stack dict dict dict\n",
      "ground_truth:\tnumpy.zeros((3, 3, 3))\n",
      "\n",
      "intent:cut off the last word of a sentence `content`\n",
      "predicted:\t'string_escape' 'string_escape' hours 'string_escape' hours 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' hours each 'string_escape' 'string_escape' genfromtxt __init__ __init__ __init__ genfromtxt __init__ __init__ __init__\n",
      "ground_truth:\t\"\"\" \"\"\".join(content.split(' ')[:-1])\n",
      "\n",
      "intent:convert scalar `x` to array\n",
      "predicted:\teach each Popen dict else True 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' True True True getcwd each getcwd getcwd else key 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' each 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore' 'ignore'\n",
      "ground_truth:\tx = np.asarray(x).reshape(1, -1)[(0), :]\n",
      "\n",
      "intent:sum all elements of nested list `L`\n",
      "predicted:\tconcatenate concatenate concatenate concatenate concatenate getcwd getcwd getcwd getcwd getcwd unpack unpack unpack concatenate concatenate concatenate concatenate concatenate bool environ environ args else concatenate concatenate concatenate unpack unpack getcwd getcwd getcwd getcwd unpack unpack unpack unpack tuple unpack unpack concatenate unpack unpack unpack unpack else concatenate concatenate unpack getcwd getcwd\n",
      "ground_truth:\tsum(sum(i) if isinstance(i, list) else i for i in L)\n",
      "\n",
      "intent:convert hex string '470FC614' to a float number\n",
      "predicted:\teach level level each with level with with with with each level level with with level with with level with with with with with with with with with with with with with with with with with now now now now dict dict with level with with with with with with\n",
      "ground_truth:\tstruct.unpack('!f', '470FC614'.decode('hex'))[0]\n",
      "\n",
      "intent:Multiple each value by `2` for all keys in a dictionary `my_dict`\n",
      "predicted:\teach with with with with now now now f f f f unpack unpack unpack hours hours hours startswith startswith startswith hours Counter concatenate concatenate getcwd concatenate __init__ getcwd ~ ~ unpack unpack unpack unpack unpack concatenate concatenate unpack unpack concatenate concatenate else else tuple tuple find_element_by_id tuple tuple tuple\n",
      "ground_truth:\tmy_dict.update((x, y * 2) for x, y in list(my_dict.items()))\n",
      "\n",
      "intent:running bash script 'sleep.sh'\n",
      "predicted:\teach each next 0.1 __init__ unpack unpack 5 unpack unpack 5 each __init__ __init__ unpack unpack unpack unpack 5 5 unpack unpack 5 unpack unpack hours hours hours hours hours hours __init__ each each each __init__ __init__ __init__ __init__ __init__ __init__ __init__ __init__ unpack unpack unpack 5 hours hours hours\n",
      "ground_truth:\tsubprocess.call('sleep.sh', shell=True)\n",
      "\n",
      "intent:Join elements of list `l` with a comma `,`\n",
      "predicted:\tfind_element_by_id ix ix params chdir chdir chdir tuple ) args tuple args False 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' not not each ) each 'string_escape' 'string_escape' 'string_escape' dot 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' not 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape' 'string_escape'\n",
      "ground_truth:\t\"\"\",\"\"\".join(l)\n",
      "\n",
      "intent:make a comma-separated string from a list `myList`\n",
      "predicted:\tgenfromtxt Popen max max max genfromtxt not __init__ __init__ genfromtxt getcwd max max max max getcwd 5 append genfromtxt each getcwd stack stack tuple tuple getcwd tuple each dirnames stack tuple stack tuple tuple getcwd stack stack tuple with != with tuple getcwd getcwd filenames tuple getcwd max max max\n",
      "ground_truth:\tmyList = ','.join(map(str, myList))\n",
      "\n",
      "intent:reverse the list that contains 1 to 10\n",
      "predicted:\teach with each genfromtxt with with with with with call with genfromtxt genfromtxt walk drop drop with with with each each each groupby groupby each drop with each genfromtxt with with genfromtxt with with with with with with with with bin with href with with with with with with with\n",
      "ground_truth:\tlist(reversed(list(range(10))))\n",
      "\n",
      "intent:remove substring 'bag,' from a string 'lamp, bag, mirror'\n",
      "predicted:\teach p each p each each p read_csv chr tuple tuple tuple finditer args read_csv tuple finditer tuple tuple args tuple finditer finditer finditer tuple tuple finditer tuple finditer read_csv tuple read_csv finditer tuple tuple reduce reduce tuple reduce reduce search ast ast 'name' params tuple tuple reduce reduce reduce\n",
      "ground_truth:\tprint('lamp, bag, mirror'.replace('bag,', ''))\n",
      "\n",
      "intent:Reverse the order of words, delimited by `.`, in string `s`\n",
      "predicted:\tconcatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate find_element_by_id unpack unpack concatenate concatenate concatenate driver concatenate concatenate concatenate concatenate bool 5 concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate concatenate driver concatenate\n",
      "ground_truth:\t\"\"\".\"\"\".join(s.split('.')[::-1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos = special_symbols['code_sos']\n",
    "eos = special_symbols['code_eos']\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    seq = model.greedy_decode(src_seq, sos, eos)\n",
    "    gen_code_tokens = code_intent_pair.idx2code(seq)\n",
    "    gen_code = sub_slotmap(gen_code_tokens, slot_map)\n",
    "    print('intent:'+intent)\n",
    "    print('predicted:\\t'+gen_code+'\\nground_truth:\\t'+code)\n",
    "    print()\n",
    "    \n",
    "    if i == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
