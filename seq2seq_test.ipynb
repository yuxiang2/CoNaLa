{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.processor import Code_Intent_Pairs, sub_slotmap\n",
    "from seq2seq2.model import Seq2Seq\n",
    "from seq2seq2.data import get_train_loader, get_test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## training parameters\n",
    "    'batch_size' : 32,\n",
    "    'lr' : 1e-4,\n",
    "    'teacher_force_rate' : 0.85,\n",
    "    'max_epochs' : 20,\n",
    "    'lr_keep_rate' : 0.95,  # set to 1.0 to not decrease lr overtime\n",
    "    \n",
    "    ## encoder architecture\n",
    "    'encoder_layers' : 2,\n",
    "    'encoder_embed_size' : 128,\n",
    "    'encoder_hidden_size' : 384,\n",
    "    'encoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## decoder architecture\n",
    "    'decoder_layers' : 2,\n",
    "    'decoder_embed_size' : 128,\n",
    "    'decoder_hidden_size' : 384,\n",
    "    'decoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## attn architecture\n",
    "    'attn_hidden_size' : 384,\n",
    "    \n",
    "    ## visualization\n",
    "    'print_every': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_intent_pair = Code_Intent_Pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vocab/'\n",
    "code_intent_pair.load_dict(path)\n",
    "special_symbols = code_intent_pair.get_special_symbols()\n",
    "word_size = code_intent_pair.get_word_size()\n",
    "code_size = code_intent_pair.get_code_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'processed_corpus/train.json'\n",
    "train_entries = code_intent_pair.load_entries(train_path)\n",
    "code_intent_pair.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = get_train_loader(train_entries, special_symbols, hyperP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'processed_corpus/test.json'\n",
    "test_entries = code_intent_pair.load_entries(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_loader(test_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(word_size, code_size, hyperP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperP['lr'])\n",
    "loss_f = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_keep_rate = hyperP['lr_keep_rate']\n",
    "if lr_keep_rate != 1.0:\n",
    "    lr_reduce_f = lambda epoch: lr_keep_rate ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_reduce_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, loss_f, hyperP):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(trainloader):\n",
    "        logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "        loss = loss_f(logits, original_out_seq)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show stats\n",
    "        loss_sum += loss.item()\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        total_correct += (predictions == original_out_seq).sum()\n",
    "        size += len(original_out_seq)\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            print('Train: loss:{}\\tacc:{}'.format(loss_sum/print_every, float(total_correct)/size), end='\\r')\n",
    "            loss_sum = 0\n",
    "            total_correct = 0\n",
    "            size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, validloader, loss_f, hyperP):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(validloader):\n",
    "            logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "            loss = loss_f(logits, original_out_seq)\n",
    "\n",
    "            # show stats\n",
    "            loss_sum += loss.item()\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            total_correct += (predictions == original_out_seq).sum()\n",
    "            size += len(original_out_seq)\n",
    "\n",
    "    print('Valid: loss:{}\\tacc:{}'.format(loss_sum/len(validloader), float(total_correct)/size), end='\\r')\n",
    "    return float(total_correct)/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: loss:2.6533851718902586\tacc:0.39269836596496394\n",
      "model saved\n",
      "Valid: loss:2.5418078819910686\tacc:0.40965699985278964\n",
      "model saved\n",
      "Valid: loss:2.4568390878041586\tacc:0.42841160017665247\n",
      "model saved\n",
      "Valid: loss:2.3800559059778847\tacc:0.44010010304725455\n",
      "model saved\n",
      "Valid: loss:2.2797077385584514\tacc:0.45641101133519855\n",
      "model saved\n",
      "Valid: loss:2.2322295268376666\tacc:0.45938466068011186\n",
      "model saved\n",
      "Valid: loss:2.1593027369181317\tacc:0.47228028853231277\n",
      "model saved\n",
      "Valid: loss:2.097739086151123\tacc:0.483586044457529856\n",
      "model saved\n",
      "Valid: loss:2.076807084083557\tacc:0.484704843220962746\n",
      "model saved\n",
      "Valid: loss:2.022046955426534\tacc:0.495627852200794974\n",
      "model saved\n",
      "Valid: loss:1.9812824646631877\tacc:0.50557927278080373\n",
      "model saved\n",
      "Valid: loss:1.9510851414998371\tacc:0.50755189165317246\n",
      "model saved\n",
      "Valid: loss:1.9111504173278808\tacc:0.51391137936110786\n",
      "model saved\n",
      "Valid: loss:1.9007323853174845\tacc:0.51591344030619763\n",
      "model saved\n",
      "Valid: loss:1.840481309890747\tacc:0.527984690122184625\n",
      "model saved\n",
      "Valid: loss:1.8116225385665894\tacc:0.53387310466656864\n",
      "model saved\n",
      "Train: loss:2.0692554235458376\tacc:0.48110524177163755\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-329906665c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-067be67f7c4a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, loss_f, hyperP)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_out_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for e in range(20):\n",
    "    train(model, trainloader, optimizer, loss_f, hyperP)\n",
    "    acc = valid(model, trainloader, loss_f, hyperP)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        model.save()\n",
    "        print()\n",
    "        print('model saved')\n",
    "    if lr_keep_rate != 1.0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tsend a signal `signal.SIGUSR1` to the current process\n",
      "predicted:\tos . <unk> ( 'signal.SIGUSR1' )\n",
      "ground_truth:\tos.kill(os.getpid(), signal.SIGUSR1)\n",
      "\n",
      "intent:\tdecode a hex string '4a4b4c' to UTF-8.\n",
      "predicted:\t\"\"\"str_0\"\"\" . split ( )\n",
      "ground_truth:\tbytes.fromhex('4a4b4c').decode('utf-8')\n",
      "\n",
      "intent:\tcheck if all elements in list `myList` are identical\n",
      "predicted:\t[ ( i , myList ) for i in myList ]\n",
      "ground_truth:\tall(x == myList[0] for x in myList)\n",
      "\n",
      "intent:\tformat number of spaces between strings `Python`, `:` and `Very Good` to be `20`\n",
      "predicted:\tPython . <unk> ( ':' , 'Very Good' )\n",
      "ground_truth:\tprint('%*s : %*s' % (20, 'Python', 20, 'Very Good'))\n",
      "\n",
      "intent:\tHow to convert a string from CP-1251 to UTF-8?\n",
      "predicted:\t<unk> . <unk> ( <unk> , <unk> )\n",
      "ground_truth:\td.decode('cp1251').encode('utf8')\n",
      "\n",
      "intent:\tget rid of None values in dictionary `kwargs`\n",
      "predicted:\tkwargs . <unk> ( )\n",
      "ground_truth:\tres = {k: v for k, v in list(kwargs.items()) if v is not None}\n",
      "\n",
      "intent:\tget rid of None values in dictionary `kwargs`\n",
      "predicted:\tkwargs . <unk> ( )\n",
      "ground_truth:\tres = dict((k, v) for k, v in kwargs.items() if v is not None)\n",
      "\n",
      "intent:\tcapture final output of a chain of system commands `ps -ef | grep something | wc -l`\n",
      "predicted:\t<unk> . <unk> ( <unk> )\n",
      "ground_truth:\tsubprocess.check_output('ps -ef | grep something | wc -l', shell=True)\n",
      "\n",
      "intent:\tconcatenate a list of strings `['a', 'b', 'c']`\n",
      "predicted:\t[ ['a', 'b', 'c'] ]\n",
      "ground_truth:\t\"\"\"\"\"\".join(['a', 'b', 'c'])\n",
      "\n",
      "intent:\tfind intersection data between series `s1` and series `s2`\n",
      "predicted:\ts2 . <unk> ( s1 , s2 )\n",
      "ground_truth:\tpd.Series(list(set(s1).intersection(set(s2))))\n",
      "\n",
      "intent:\tsending http headers to `client`\n",
      "predicted:\tclient . <unk> ( <unk> )\n",
      "ground_truth:\tclient.send('HTTP/1.0 200 OK\\r\\n')\n",
      "\n",
      "intent:\tFormat a datetime string `when` to extract date only\n",
      "predicted:\twhen . decode ( <unk> )\n",
      "ground_truth:\tthen = datetime.datetime.strptime(when, '%Y-%m-%d').date()\n",
      "\n",
      "intent:\tsplit a multi-line string `inputString` into separate strings\n",
      "predicted:\tre . sub ( <unk> , inputString )\n",
      "ground_truth:\tinputString.split('\\n')\n",
      "\n",
      "intent:\tSplit a multi-line string ` a \\n b \\r\\n c ` by new line character `\\n`\n",
      "predicted:\tre . split ( 'a \n",
      " b \n",
      " c' , '\n",
      "' )\n",
      "ground_truth:\t' a \\n b \\r\\n c '.split('\\n')\n",
      "\n",
      "intent:\tconcatenate elements of list `b` by a colon \":\"\n",
      "predicted:\tb . join ( b )\n",
      "ground_truth:\t\"\"\":\"\"\".join(str(x) for x in b)\n",
      "\n",
      "intent:\tget the first object from a queryset in django model `Entry`\n",
      "predicted:\tEntry . <unk> ( Entry )\n",
      "ground_truth:\tEntry.objects.filter()[:1].get()\n",
      "\n",
      "intent:\tCalculate sum over all rows of 2D numpy array\n",
      "predicted:\tnp . <unk> ( [ ( <unk> , 3 ) )\n",
      "ground_truth:\ta.sum(axis=1)\n",
      "\n",
      "intent:\tenable warnings using action 'always'\n",
      "predicted:\t<unk> . <unk> ( 'always' )\n",
      "ground_truth:\twarnings.simplefilter('always')\n",
      "\n",
      "intent:\tconcatenate items of list `l` with a space ' '\n",
      "predicted:\tl . join ( <unk> )\n",
      "ground_truth:\tprint(' '.join(map(str, l)))\n",
      "\n",
      "intent:\trun script 'hello.py' with argument 'htmlfilename.htm' on terminal using python executable\n",
      "predicted:\t<unk> . <unk> ( 'hello.py' , <unk> = <unk> )\n",
      "ground_truth:\tsubprocess.call(['python.exe', 'hello.py', 'htmlfilename.htm'])\n",
      "\n",
      "intent:\tHow can I parse a time string containing milliseconds in it with python?\n",
      "predicted:\tdatetime . datetime . strptime ( <unk> )\n",
      "ground_truth:\ttime.strptime('30/03/09 16:31:32.123', '%d/%m/%y %H:%M:%S.%f')\n",
      "\n",
      "intent:\tconvert a string `my_string` with dot and comma into a float number `my_float`\n",
      "predicted:\tre . join ( <unk> , my_string )\n",
      "ground_truth:\tmy_float = float(my_string.replace(',', ''))\n",
      "\n",
      "intent:\tconvert a string `123,456.908` with dot and comma into a floating number\n",
      "predicted:\tre . findall ( <unk> , '123,456.908' )\n",
      "ground_truth:\tfloat('123,456.908'.replace(',', ''))\n",
      "\n",
      "intent:\tset pythonpath in python script.\n",
      "predicted:\t<unk> . <unk> ( <unk> , <unk> )\n",
      "ground_truth:\tsys.path.append('/path/to/whatever')\n",
      "\n",
      "intent:\tsplit string 'Words, words, words.' using a regex '(\\\\W+)'\n",
      "predicted:\tre . findall ( 'Words, words, words.' , '(\\W+)' )\n",
      "ground_truth:\tre.split('(\\\\W+)', 'Words, words, words.')\n",
      "\n",
      "intent:\topen a file `Output.txt` in append mode\n",
      "predicted:\tos . path . <unk> ( 'Output.txt' , 'str_1' )\n",
      "ground_truth:\tfile = open('Output.txt', 'a')\n",
      "\n",
      "intent:\tdownload a file \"http://www.example.com/songs/mp3.mp3\" over HTTP and save to \"mp3.mp3\"\n",
      "predicted:\t<unk> . <unk> ( 'http://www.example.com/songs/mp3.mp3' , 'mp3.mp3' )\n",
      "ground_truth:\turllib.request.urlretrieve('http://www.example.com/songs/mp3.mp3', 'mp3.mp3')\n",
      "\n",
      "intent:\tdownload a file `url` over HTTP and save to `file_name`\n",
      "predicted:\tfile_name . <unk> ( url , file_name )\n",
      "ground_truth:\tu = urllib.request.urlopen(url)\n",
      "f = open(file_name, 'wb')\n",
      "meta = u.info()\n",
      "file_size = int(meta.getheaders('Content-Length')[0])\n",
      "print(('Downloading: %s Bytes: %s' % (file_name, file_size)))\n",
      "file_size_dl = 0\n",
      "block_sz = 8192\n",
      "while True:\n",
      "    buffer = u.read(block_sz)\n",
      "    if (not buffer):\n",
      "        break\n",
      "    file_size_dl += len(buffer)\n",
      "    f.write(buffer)\n",
      "    status = ('%10d  [%3.2f%%]' % (file_size_dl, ((file_size_dl * 100.0) / file_size)))\n",
      "    status = (status + (chr(8) * (len(status) + 1)))\n",
      "    print(status, end=' ')\n",
      "f.close()\n",
      "\n",
      "intent:\tdownload a file 'http://www.example.com/' over HTTP\n",
      "predicted:\tos . path . path ( 'http://www.example.com/' , <unk> )\n",
      "ground_truth:\tresponse = urllib.request.urlopen('http://www.example.com/')\n",
      "html = response.read()\n",
      "\n",
      "intent:\tdownload a file `url` over HTTP\n",
      "predicted:\turl . <unk> ( url )\n",
      "ground_truth:\tr = requests.get(url)\n",
      "\n",
      "intent:\tdownload a file `url` over HTTP and save to \"10MB\"\n",
      "predicted:\turl . <unk> ( '10MB' , <unk> = <unk> )\n",
      "ground_truth:\tresponse = requests.get(url, stream=True)\n",
      "with open('10MB', 'wb') as handle:\n",
      "    for data in tqdm(response.iter_content()):\n",
      "        handle.write(data)\n",
      "\n",
      "intent:\targparse add argument with flag '--version' and version action of '%(prog)s 2.0' to parser `parser`\n",
      "predicted:\tparser . <unk> ( <unk> , <unk> , <unk> )\n",
      "ground_truth:\tparser.add_argument('--version', action='version', version='%(prog)s 2.0')\n",
      "\n",
      "intent:\tremove key 'c' from dictionary `d`\n",
      "predicted:\td . join ( d . items ( ) )\n",
      "ground_truth:\t{i: d[i] for i in d if i != 'c'}\n",
      "\n",
      "intent:\tCreate new DataFrame object by merging columns \"key\" of  dataframes `split_df` and `csv_df` and rename the columns from dataframes `split_df` and `csv_df` with suffix `_left` and `_right` respectively\n",
      "predicted:\tsplit_df . groupby ( [ 'key' , 'csv_df' ] , <unk> = <unk> , <unk> = <unk> )\n",
      "ground_truth:\tpd.merge(split_df, csv_df, on=['key'], suffixes=('_left', '_right'))\n",
      "\n",
      "intent:\tSplit a string `s` by space with `4` splits\n",
      "predicted:\tre . join ( s . split ( ) )\n",
      "ground_truth:\ts.split(' ', 4)\n",
      "\n",
      "intent:\tread keyboard-input\n",
      "predicted:\t<unk> . <unk> ( <unk> )\n",
      "ground_truth:\tinput('Enter your input:')\n",
      "\n",
      "intent:\tenable debug mode on Flask application `app`\n",
      "predicted:\tapp . <unk> ( <unk> )\n",
      "ground_truth:\tapp.run(debug=True)\n",
      "\n",
      "intent:\tpython save list `mylist` to file object 'save.txt'\n",
      "predicted:\tmylist . <unk> ( 'save.txt' )\n",
      "ground_truth:\tpickle.dump(mylist, open('save.txt', 'wb'))\n",
      "\n",
      "intent:\tMultiply a matrix `P` with a 3d tensor `T` in scipy\n",
      "predicted:\tP . <unk> ( <unk> , T )\n",
      "ground_truth:\tscipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)\n",
      "\n",
      "intent:\tCreate 3d array of zeroes of size `(3,3,3)`\n",
      "predicted:\t<unk> . <unk> ( <unk> , <unk> )\n",
      "ground_truth:\tnumpy.zeros((3, 3, 3))\n",
      "\n",
      "intent:\tcut off the last word of a sentence `content`\n",
      "predicted:\tcontent . <unk> ( <unk> )\n",
      "ground_truth:\t\"\"\" \"\"\".join(content.split(' ')[:-1])\n",
      "\n",
      "intent:\tconvert scalar `x` to array\n",
      "predicted:\tx . <unk> ( <unk> , <unk> )\n",
      "ground_truth:\tx = np.asarray(x).reshape(1, -1)[(0), :]\n",
      "\n",
      "intent:\tsum all elements of nested list `L`\n",
      "predicted:\t[ ( L ) for i in L ]\n",
      "ground_truth:\tsum(sum(i) if isinstance(i, list) else i for i in L)\n",
      "\n",
      "intent:\tconvert hex string '470FC614' to a float number\n",
      "predicted:\tint ( '470FC614' , 16 )\n",
      "ground_truth:\tstruct.unpack('!f', '470FC614'.decode('hex'))[0]\n",
      "\n",
      "intent:\tMultiple each value by `2` for all keys in a dictionary `my_dict`\n",
      "predicted:\tmy_dict . join ( <unk> , v ) for k in my_dict . items ( ) )\n",
      "ground_truth:\tmy_dict.update((x, y * 2) for x, y in list(my_dict.items()))\n",
      "\n",
      "intent:\trunning bash script 'sleep.sh'\n",
      "predicted:\tos . system ( 'sleep.sh' )\n",
      "ground_truth:\tsubprocess.call('sleep.sh', shell=True)\n",
      "\n",
      "intent:\tJoin elements of list `l` with a comma `,`\n",
      "predicted:\tl . join ( ',' )\n",
      "ground_truth:\t\"\"\",\"\"\".join(l)\n",
      "\n",
      "intent:\tmake a comma-separated string from a list `myList`\n",
      "predicted:\t[ i for i in myList ]\n",
      "ground_truth:\tmyList = ','.join(map(str, myList))\n",
      "\n",
      "intent:\treverse the list that contains 1 to 10\n",
      "predicted:\t[ ( x , 2 ) for x in range ( ) )\n",
      "ground_truth:\tlist(reversed(list(range(10))))\n",
      "\n",
      "intent:\tremove substring 'bag,' from a string 'lamp, bag, mirror'\n",
      "predicted:\tre . sub ( 'bag,' , 'lamp, bag, mirror' )\n",
      "ground_truth:\tprint('lamp, bag, mirror'.replace('bag,', ''))\n",
      "\n",
      "intent:\tReverse the order of words, delimited by `.`, in string `s`\n",
      "predicted:\ts . sub ( '.' , '' )\n",
      "ground_truth:\t\"\"\".\"\"\".join(s.split('.')[::-1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos = special_symbols['code_sos']\n",
    "eos = special_symbols['code_eos']\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    model.eval()\n",
    "    seq = model.greedy_decode(src_seq, sos, eos)\n",
    "    gen_code_tokens = code_intent_pair.idx2code(seq)\n",
    "    gen_code = sub_slotmap(gen_code_tokens, slot_map)\n",
    "    print('intent:\\t'+intent)\n",
    "    print('predicted:\\t'+gen_code+'\\nground_truth:\\t'+code)\n",
    "    print()\n",
    "    \n",
    "    if i == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
