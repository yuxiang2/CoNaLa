{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.processor import Code_Intent_Pairs, sub_slotmap\n",
    "from seq2seq2.model import Seq2Seq\n",
    "from seq2seq2.data import get_train_loader, get_test_loader, write_answer_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## training parameters\n",
    "    'batch_size' : 32,\n",
    "    'lr' : 1e-4,\n",
    "    'teacher_force_rate' : 0.85,\n",
    "    'max_epochs' : 20,\n",
    "    'lr_keep_rate' : 0.95,  # set to 1.0 to not decrease lr overtime\n",
    "    \n",
    "    ## encoder architecture\n",
    "    'encoder_layers' : 2,\n",
    "    'encoder_embed_size' : 128,\n",
    "    'encoder_hidden_size' : 384,\n",
    "    'encoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## decoder architecture\n",
    "    'decoder_layers' : 2,\n",
    "    'decoder_embed_size' : 128,\n",
    "    'decoder_hidden_size' : 384,\n",
    "    'decoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## attn architecture\n",
    "    'attn_hidden_size' : 384,\n",
    "    \n",
    "    ## visualization\n",
    "    'print_every': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_intent_pair = Code_Intent_Pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vocab/'\n",
    "code_intent_pair.load_dict(path)\n",
    "special_symbols = code_intent_pair.get_special_symbols()\n",
    "word_size = code_intent_pair.get_word_size()\n",
    "code_size = code_intent_pair.get_code_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'processed_corpus/train.json'\n",
    "train_entries = code_intent_pair.load_entries(train_path)\n",
    "code_intent_pair.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = get_train_loader(train_entries, special_symbols, hyperP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'processed_corpus/test.json'\n",
    "test_entries = code_intent_pair.load_entries(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_loader(test_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(word_size, code_size, hyperP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperP['lr'])\n",
    "loss_f = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_keep_rate = hyperP['lr_keep_rate']\n",
    "if lr_keep_rate != 1.0:\n",
    "    lr_reduce_f = lambda epoch: lr_keep_rate ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lr_reduce_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, loss_f, hyperP):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(trainloader):\n",
    "        logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "        loss = loss_f(logits, original_out_seq)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show stats\n",
    "        loss_sum += loss.item()\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        total_correct += (predictions == original_out_seq).sum()\n",
    "        size += len(original_out_seq)\n",
    "\n",
    "        if (i+1) % print_every == 0:\n",
    "            print('Train: loss:{}\\tacc:{}'.format(loss_sum/print_every, float(total_correct)/size))\n",
    "            loss_sum = 0\n",
    "            total_correct = 0\n",
    "            size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, validloader, loss_f, hyperP):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    total_correct = 0\n",
    "    size = 0\n",
    "    print_every = hyperP['print_every']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (inp_seq, original_out_seq, padded_out_seq, out_lens) in enumerate(validloader):\n",
    "            logits = model(inp_seq, padded_out_seq, out_lens)\n",
    "            loss = loss_f(logits, original_out_seq)\n",
    "\n",
    "            # show stats\n",
    "            loss_sum += loss.item()\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            total_correct += (predictions == original_out_seq).sum()\n",
    "            size += len(original_out_seq)\n",
    "\n",
    "    print('Valid: loss:{}\\tacc:{}'.format(loss_sum/len(validloader), float(total_correct)/size))\n",
    "    return float(total_correct)/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.624136543273926\tacc:0.23060796645702306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.6429473876953127\tacc:0.22873512560599382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.7524927616119386\tacc:0.21129622104835433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.6546747207641603\tacc:0.23501303214596003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.6199349880218508\tacc:0.22411474675033619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.585883045196533\tacc:0.2661113546690048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.5825339794158935\tacc:0.2607052896725441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: loss:3.7155691146850587\tacc:0.21247960848287112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f3f2d0d6eca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-056b3f70e462>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, optimizer, loss_f, hyperP)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_out_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_out_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_out_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_out_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSIN/11747-nnNLP/codeGenerator/CoNaLa/seq2seq2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src_seq, trgt_seq, out_lens)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgt_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             logits, hidden, context, _ = self.decoder(prev_token, hidden, \n\u001b[0;32m--> 127\u001b[0;31m                 encoder_outputs, encoder_outputs_reshaped, context)\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_force_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mprev_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrgt_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSIN/11747-nnNLP/codeGenerator/CoNaLa/seq2seq2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prev_token, last_hidden, encoder_outputs, encoder_outputs_reshaped, context)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (1,B,N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (1,B,N) -> (B,N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for e in range(20):\n",
    "    train(model, trainloader, optimizer, loss_f, hyperP)\n",
    "    acc = valid(model, trainloader, loss_f, hyperP)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        model.save()\n",
    "        print()\n",
    "        print('model saved')\n",
    "    if lr_keep_rate != 1.0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false,
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tsend a signal `signal.SIGUSR1` to the current process\npredicted:\t. . ( ( )\nground_truth:\tos.kill(os.getpid(), signal.SIGUSR1)\n\nintent:\tdecode a hex string '4a4b4c' to UTF-8.\npredicted:\t. ( ( )\nground_truth:\tbytes.fromhex('4a4b4c').decode('utf-8')\n\nintent:\tcheck if all elements in list `myList` are identical\npredicted:\tmyList . ( ( )\nground_truth:\tall(x == myList[0] for x in myList)\n\nintent:\tformat number of spaces between strings `Python`, `:` and `Very Good` to be `20`\npredicted:\tPython . ( ( )\nground_truth:\tprint('%*s : %*s' % (20, 'Python', 20, 'Very Good'))\n\nintent:\tHow to convert a string from CP-1251 to UTF-8?\npredicted:\t. . ( ( )\nground_truth:\td.decode('cp1251').encode('utf8')\n\nintent:\tget rid of None values in dictionary `kwargs`\npredicted:\tkwargs . ( ( )\nground_truth:\tres = {k: v for k, v in list(kwargs.items()) if v is not None}\n\nintent:\tget rid of None values in dictionary `kwargs`\npredicted:\tkwargs . ( ( )\nground_truth:\tres = dict((k, v) for k, v in kwargs.items() if v is not None)\n\nintent:\tcapture final output of a chain of system commands `ps -ef | grep something | wc -l`\npredicted:\t. . ( ( <unk> )\nground_truth:\tsubprocess.check_output('ps -ef | grep something | wc -l', shell=True)\n\nintent:\tconcatenate a list of strings `['a', 'b', 'c']`\npredicted:\t[ ( ( )\nground_truth:\t\"\"\"\"\"\".join(['a', 'b', 'c'])\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tfind intersection data between series `s1` and series `s2`\npredicted:\ts1 . ( ( )\nground_truth:\tpd.Series(list(set(s1).intersection(set(s2))))\n\nintent:\tsending http headers to `client`\npredicted:\t. . ( ( )\nground_truth:\tclient.send('HTTP/1.0 200 OK\\r\\n')\n\nintent:\tFormat a datetime string `when` to extract date only\npredicted:\twhen . ( ( )\nground_truth:\tthen = datetime.datetime.strptime(when, '%Y-%m-%d').date()\n\nintent:\tsplit a multi-line string `inputString` into separate strings\npredicted:\t. . ( ( )\nground_truth:\tinputString.split('\\n')\n\nintent:\tSplit a multi-line string ` a \\n b \\r\\n c ` by new line character `\\n`\npredicted:\t. . ( ( )\nground_truth:\t' a \\n b \\r\\n c '.split('\\n')\n\nintent:\tconcatenate elements of list `b` by a colon \":\"\npredicted:\tb . ( ( )\nground_truth:\t\"\"\":\"\"\".join(str(x) for x in b)\n\nintent:\tget the first object from a queryset in django model `Entry`\npredicted:\t. . ( ( )\nground_truth:\tEntry.objects.filter()[:1].get()\n\nintent:\tCalculate sum over all rows of 2D numpy array\npredicted:\t. ( ( )\nground_truth:\ta.sum(axis=1)\n\nintent:\tenable warnings using action 'always'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\npredicted:\t. . ( ( <unk> )\nground_truth:\twarnings.simplefilter('always')\n\nintent:\tconcatenate items of list `l` with a space ' '\npredicted:\tl . ( ( )\nground_truth:\tprint(' '.join(map(str, l)))\n\nintent:\trun script 'hello.py' with argument 'htmlfilename.htm' on terminal using python executable\npredicted:\t. . ( ( <unk> )\nground_truth:\tsubprocess.call(['python.exe', 'hello.py', 'htmlfilename.htm'])\n\nintent:\tHow can I parse a time string containing milliseconds in it with python?\npredicted:\t. . ( ( )\nground_truth:\ttime.strptime('30/03/09 16:31:32.123', '%d/%m/%y %H:%M:%S.%f')\n\nintent:\tconvert a string `my_string` with dot and comma into a float number `my_float`\npredicted:\tmy_string . ( ( )\nground_truth:\tmy_float = float(my_string.replace(',', ''))\n\nintent:\tconvert a string `123,456.908` with dot and comma into a floating number\npredicted:\t. ( ( )\nground_truth:\tfloat('123,456.908'.replace(',', ''))\n\nintent:\tset pythonpath in python script.\npredicted:\t. . ( ( )\nground_truth:\tsys.path.append('/path/to/whatever')\n\nintent:\tsplit string 'Words, words, words.' using a regex '(\\\\W+)'\npredicted:\t. ( ( )\nground_truth:\tre.split('(\\\\W+)', 'Words, words, words.')\n\nintent:\topen a file `Output.txt` in append mode\npredicted:\t. ( ( )\nground_truth:\tfile = open('Output.txt', 'a')\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tdownload a file \"http://www.example.com/songs/mp3.mp3\" over HTTP and save to \"mp3.mp3\"\npredicted:\t. ( ( )\nground_truth:\turllib.request.urlretrieve('http://www.example.com/songs/mp3.mp3', 'mp3.mp3')\n\nintent:\tdownload a file `url` over HTTP and save to `file_name`\npredicted:\turl . ( ( )\nground_truth:\tu = urllib.request.urlopen(url)\nf = open(file_name, 'wb')\nmeta = u.info()\nfile_size = int(meta.getheaders('Content-Length')[0])\nprint(('Downloading: %s Bytes: %s' % (file_name, file_size)))\nfile_size_dl = 0\nblock_sz = 8192\nwhile True:\n    buffer = u.read(block_sz)\n    if (not buffer):\n        break\n    file_size_dl += len(buffer)\n    f.write(buffer)\n    status = ('%10d  [%3.2f%%]' % (file_size_dl, ((file_size_dl * 100.0) / file_size)))\n    status = (status + (chr(8) * (len(status) + 1)))\n    print(status, end=' ')\nf.close()\n\nintent:\tdownload a file 'http://www.example.com/' over HTTP\npredicted:\t. ( ( )\nground_truth:\tresponse = urllib.request.urlopen('http://www.example.com/')\nhtml = response.read()\n\nintent:\tdownload a file `url` over HTTP\npredicted:\turl . ( ( )\nground_truth:\tr = requests.get(url)\n\nintent:\tdownload a file `url` over HTTP and save to \"10MB\"\npredicted:\turl . ( ( )\nground_truth:\tresponse = requests.get(url, stream=True)\nwith open('10MB', 'wb') as handle:\n    for data in tqdm(response.iter_content()):\n        handle.write(data)\n\nintent:\targparse add argument with flag '--version' and version action of '%(prog)s 2.0' to parser `parser`\npredicted:\t. . ( ( )\nground_truth:\tparser.add_argument('--version', action='version', version='%(prog)s 2.0')\n\nintent:\tremove key 'c' from dictionary `d`\npredicted:\td . ( ( )\nground_truth:\t{i: d[i] for i in d if i != 'c'}\n\nintent:\tCreate new DataFrame object by merging columns \"key\" of  dataframes `split_df` and `csv_df` and rename the columns from dataframes `split_df` and `csv_df` with suffix `_left` and `_right` respectively\npredicted:\tsplit_df . ( ( )\nground_truth:\tpd.merge(split_df, csv_df, on=['key'], suffixes=('_left', '_right'))\n\nintent:\tSplit a string `s` by space with `4` splits\npredicted:\ts . ( ( )\nground_truth:\ts.split(' ', 4)\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tread keyboard-input\npredicted:\t. ( ( )\nground_truth:\tinput('Enter your input:')\n\nintent:\tenable debug mode on Flask application `app`\npredicted:\t. . ( ( )\nground_truth:\tapp.run(debug=True)\n\nintent:\tpython save list `mylist` to file object 'save.txt'\npredicted:\tmylist . ( ( )\nground_truth:\tpickle.dump(mylist, open('save.txt', 'wb'))\n\nintent:\tMultiply a matrix `P` with a 3d tensor `T` in scipy\npredicted:\tP . ( ( )\nground_truth:\tscipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)\n\nintent:\tCreate 3d array of zeroes of size `(3,3,3)`\npredicted:\t. . ( ( )\nground_truth:\tnumpy.zeros((3, 3, 3))\n\nintent:\tcut off the last word of a sentence `content`\npredicted:\t. . ( ( )\nground_truth:\t\"\"\" \"\"\".join(content.split(' ')[:-1])\n\nintent:\tconvert scalar `x` to array\npredicted:\t. . ( ( )\nground_truth:\tx = np.asarray(x).reshape(1, -1)[(0), :]\n\nintent:\tsum all elements of nested list `L`\npredicted:\tL . ( ( )\nground_truth:\tsum(sum(i) if isinstance(i, list) else i for i in L)\n\nintent:\tconvert hex string '470FC614' to a float number\npredicted:\t. ( ( )\nground_truth:\tstruct.unpack('!f', '470FC614'.decode('hex'))[0]\n\nintent:\tMultiple each value by `2` for all keys in a dictionary `my_dict`\npredicted:\tmy_dict . ( ( ) )\nground_truth:\tmy_dict.update((x, y * 2) for x, y in list(my_dict.items()))\n\nintent:\trunning bash script 'sleep.sh'\npredicted:\t. ( ( )\nground_truth:\tsubprocess.call('sleep.sh', shell=True)\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:\tJoin elements of list `l` with a comma `,`\npredicted:\tl . ( ( )\nground_truth:\t\"\"\",\"\"\".join(l)\n\nintent:\tmake a comma-separated string from a list `myList`\npredicted:\tmyList . ( ( )\nground_truth:\tmyList = ','.join(map(str, myList))\n\nintent:\treverse the list that contains 1 to 10\npredicted:\tvar_0 . ( ( )\nground_truth:\tlist(reversed(list(range(10))))\n\nintent:\tremove substring 'bag,' from a string 'lamp, bag, mirror'\npredicted:\t. ( ( )\nground_truth:\tprint('lamp, bag, mirror'.replace('bag,', ''))\n\nintent:\tReverse the order of words, delimited by `.`, in string `s`\npredicted:\ts . ( ( )\nground_truth:\t\"\"\".\"\"\".join(s.split('.')[::-1])\n\n"
     ]
    }
   ],
   "source": [
    "sos = special_symbols['code_sos']\n",
    "eos = special_symbols['code_eos']\n",
    "code_list = []\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    model.eval()\n",
    "    seq = model.greedy_decode(src_seq, sos, eos)\n",
    "    gen_code_tokens = code_intent_pair.idx2code(seq)\n",
    "    gen_code = sub_slotmap(gen_code_tokens, slot_map)\n",
    "    code_list.append(gen_code)\n",
    "    print('intent:\\t'+intent)\n",
    "    print('predicted:\\t'+gen_code+'\\nground_truth:\\t'+code)\n",
    "    print()\n",
    "    \n",
    "    # if i == 50:\n",
    "    #     break\n",
    "write_answer_json(code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
