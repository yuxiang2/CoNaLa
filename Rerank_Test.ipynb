{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./preprocessing')\n",
    "sys.path.append('./seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import Code_Intent_Pairs\n",
    "from model import Seq2Seq\n",
    "from data import get_test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_intent_pair = Code_Intent_Pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vocab/'\n",
    "code_intent_pair.load_dict(path)\n",
    "special_symbols = code_intent_pair.get_special_symbols()\n",
    "word_size = code_intent_pair.get_word_size()\n",
    "code_size = code_intent_pair.get_code_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'processed_corpus/test.json'\n",
    "test_entries = code_intent_pair.load_entries(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_loader(test_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## training parameters\n",
    "    'batch_size' : 32,\n",
    "    'lr' : 1e-3,\n",
    "    'teacher_force_rate' : 0.90,\n",
    "    'max_epochs' : 50,\n",
    "    'lr_keep_rate' : 0.95,  # set to 1.0 to not decrease lr overtime\n",
    "    'load_pretrain_code_embed': False,\n",
    "    'freeze_embed': False,\n",
    "    \n",
    "    ## encoder architecture\n",
    "    'encoder_layers' : 2,\n",
    "    'encoder_embed_size' : 128,\n",
    "    'encoder_hidden_size' : 384,\n",
    "    'encoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## decoder architecture\n",
    "    'decoder_layers' : 2,\n",
    "    'decoder_embed_size' : 128,\n",
    "    'decoder_hidden_size' : 384,\n",
    "    'decoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## attn architecture\n",
    "    'attn_hidden_size' : 384,\n",
    "    \n",
    "    ## visualization\n",
    "    'print_every': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(word_size, code_size, hyperP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if hyperP['load_pretrain_code_embed']:\n",
    "    model.decoder.embed[0].load_state_dict(torch.load('./pretrain_code_lm/embedding-1556211835.t7'))\n",
    "    if hyperP['freeze_embed']:\n",
    "        for param in model.decoder.embed[0].parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('model_30.t7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import Decoder\n",
    "from decoder import post_process_dummy, post_process_pmi\n",
    "from evaluate import get_bleu_all, get_bleu_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_decoder = Decoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sos = special_symbols['code_sos']\n",
    "eos = special_symbols['code_eos']\n",
    "unk = special_symbols['code_unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2code = code_intent_pair.idx2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent2idx = code_intent_pair.intent2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=3)\n",
    "    dummy_code =  post_process_dummy(slot_map, beams, idx2code)\n",
    "    dummy_code_list.append(dummy_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2726735512450424"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(dummy_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerank with PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('pmi_matrix', 'rb') as f:\n",
    "    pmi = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import process_intent\n",
    "\n",
    "pmi_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=3)\n",
    "    pmi_code =  post_process_pmi(intent, beams, \n",
    "                                 idx2code, intent2idx, pmi, process_intent)\n",
    "    \n",
    "    pmi_code_list.append(pmi_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2891773196832087"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(pmi_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from processor import process_intent\n",
    "\n",
    "pmi_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=20)\n",
    "    pmi_code =  post_process_pmi(intent, beams, \n",
    "                                 idx2code, intent2idx, pmi, process_intent)\n",
    "    \n",
    "    pmi_code_list.append(pmi_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32096633902279686"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(pmi_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:     \t send a signal `signal.SIGUSR1` to the current process\n",
      "groud trugh:\t os.kill(os.getpid(), signal.SIGUSR1)\n",
      "prediction: \t try : \n",
      "      print ( ) \n",
      "  except : \n",
      "      print ( 'signal.SIGUSR1' ) \n",
      "  except : \n",
      "      print ( ) ) \n",
      "  except : . write ( )\n",
      "\n",
      "intent:     \t decode a hex string '4a4b4c' to UTF-8.\n",
      "groud trugh:\t bytes.fromhex('4a4b4c').decode('utf-8')\n",
      "prediction: \t \"\"\"4a4b4c\"\"\" . encode ( 'hex' ) . decode ( 'utf8' )\n",
      "\n",
      "intent:     \t check if all elements in list `myList` are identical\n",
      "groud trugh:\t all(x == myList[0] for x in myList)\n",
      "prediction: \t all ( isinstance ( word , myList ) ) == 1\n",
      "\n",
      "intent:     \t format number of spaces between strings `Python`, `:` and `Very Good` to be `20`\n",
      "groud trugh:\t print('%*s : %*s' % (20, 'Python', 20, 'Very Good'))\n",
      "prediction: \t print ( re . sub ( '(:)' , 'Very Good' , Python ) )\n",
      "\n",
      "intent:     \t How to convert a string from CP-1251 to UTF-8?\n",
      "groud trugh:\t d.decode('cp1251').encode('utf8')\n",
      "prediction: \t s . format . encode ( ) . decode ( 'utf-8' )\n",
      "\n",
      "intent:     \t get rid of None values in dictionary `kwargs`\n",
      "groud trugh:\t res = {k: v for k, v in list(kwargs.items()) if v is not None}\n",
      "prediction: \t next ( iter ( list ( kwargs . values ( ) ) ) )\n",
      "\n",
      "intent:     \t get rid of None values in dictionary `kwargs`\n",
      "groud trugh:\t res = dict((k, v) for k, v in kwargs.items() if v is not None)\n",
      "prediction: \t next ( iter ( list ( kwargs . values ( ) ) ) )\n",
      "\n",
      "intent:     \t capture final output of a chain of system commands `ps -ef | grep something | wc -l`\n",
      "groud trugh:\t subprocess.check_output('ps -ef | grep something | wc -l', shell=True)\n",
      "prediction: \t subprocess . call ( [ 'shutdown' , 'ps -ef | grep something | wc -l' ] , stderr = subprocess . STDOUT )\n",
      "\n",
      "intent:     \t concatenate a list of strings `['a', 'b', 'c']`\n",
      "groud trugh:\t \"\"\"\"\"\".join(['a', 'b', 'c'])\n",
      "prediction: \t \"\"\"\"\"\" . join ( [ ['a', 'b', 'c'] ] )\n",
      "\n",
      "intent:     \t find intersection data between series `s1` and series `s2`\n",
      "groud trugh:\t pd.Series(list(set(s1).intersection(set(s2))))\n",
      "prediction: \t s2 . set_index ( [ 's1' , 's2' ] ) . size ( )\n",
      "\n",
      "intent:     \t sending http headers to `client`\n",
      "groud trugh:\t client.send('HTTP/1.0 200 OK\\r\\n')\n",
      "prediction: \t client = requests . execute ( client )\n",
      "\n",
      "intent:     \t Format a datetime string `when` to extract date only\n",
      "groud trugh:\t then = datetime.datetime.strptime(when, '%Y-%m-%d').date()\n",
      "prediction: \t datetime . datetime . strptime ( when , datetime ) . strftime ( 'utf8' )\n",
      "\n",
      "intent:     \t split a multi-line string `inputString` into separate strings\n",
      "groud trugh:\t inputString.split('\\n')\n",
      "prediction: \t l = map ( int , re . findall ( ) , inputString ) )\n",
      "\n",
      "intent:     \t Split a multi-line string ` a \\n b \\r\\n c ` by new line character `\\n`\n",
      "groud trugh:\t ' a \\n b \\r\\n c '.split('\\n')\n",
      "prediction: \t re . split ( '\\n' , 'a \\n b \\r\\n c' )\n",
      "\n",
      "intent:     \t concatenate elements of list `b` by a colon \":\"\n",
      "groud trugh:\t \"\"\":\"\"\".join(str(x) for x in b)\n",
      "prediction: \t b = [ x . split ( ':' ) [ - 1 ] for x in b ]\n",
      "\n",
      "intent:     \t get the first object from a queryset in django model `Entry`\n",
      "groud trugh:\t Entry.objects.filter()[:1].get()\n",
      "prediction: \t Entry . objects . where ( ) . order_by ( )\n",
      "\n",
      "intent:     \t Calculate sum over all rows of 2D numpy array\n",
      "groud trugh:\t a.sum(axis=1)\n",
      "prediction: \t numpy . dot ( a , list ( range ( 1 , 2 ) ) , axis = 1 )\n",
      "\n",
      "intent:     \t enable warnings using action 'always'\n",
      "groud trugh:\t warnings.simplefilter('always')\n",
      "prediction: \t print . format . click ( 'always' )\n",
      "\n",
      "intent:     \t concatenate items of list `l` with a space ' '\n",
      "groud trugh:\t print(' '.join(map(str, l)))\n",
      "prediction: \t l = list ( '' )\n",
      "\n",
      "intent:     \t run script 'hello.py' with argument 'htmlfilename.htm' on terminal using python executable\n",
      "groud trugh:\t subprocess.call(['python.exe', 'hello.py', 'htmlfilename.htm'])\n",
      "prediction: \t subprocess . call ( [ 'htmlfilename.htm' , 'htmlfilename.htm' , 'hello.py' ] )\n",
      "\n",
      "intent:     \t How can I parse a time string containing milliseconds in it with python?\n",
      "groud trugh:\t time.strptime('30/03/09 16:31:32.123', '%d/%m/%y %H:%M:%S.%f')\n",
      "prediction: \t re . replace ( '_' , '' )\n",
      "\n",
      "intent:     \t convert a string `my_string` with dot and comma into a float number `my_float`\n",
      "groud trugh:\t my_float = float(my_string.replace(',', ''))\n",
      "prediction: \t my_float = my_string . replace ( ',' , my_float )\n",
      "\n",
      "intent:     \t convert a string `123,456.908` with dot and comma into a floating number\n",
      "groud trugh:\t float('123,456.908'.replace(',', ''))\n",
      "prediction: \t ast . literal_eval ( '123,456.908' )\n",
      "\n",
      "intent:     \t set pythonpath in python script.\n",
      "groud trugh:\t sys.path.append('/path/to/whatever')\n",
      "prediction: \t subprocess . call ( [ 'shutdown' , str , ] ] )\n",
      "\n",
      "intent:     \t split string 'Words, words, words.' using a regex '(\\\\W+)'\n",
      "groud trugh:\t re.split('(\\\\W+)', 'Words, words, words.')\n",
      "prediction: \t re . compile ( '(\\\\W+)' , re . IGNORECASE ) . split ( 'Words, words, words.' )\n",
      "\n",
      "intent:     \t open a file `Output.txt` in append mode\n",
      "groud trugh:\t file = open('Output.txt', 'a')\n",
      "prediction: \t output . open ( 'Output.txt' , 'r' , 'str_1' = 'utf-8' )\n",
      "\n",
      "intent:     \t download a file \"http://www.example.com/songs/mp3.mp3\" over HTTP and save to \"mp3.mp3\"\n",
      "groud trugh:\t urllib.request.urlretrieve('http://www.example.com/songs/mp3.mp3', 'mp3.mp3')\n",
      "prediction: \t urllib . request . urlretrieve ( 'http://www.example.com/songs/mp3.mp3' , 'mp3.mp3' ) . read ( )\n",
      "\n",
      "intent:     \t download a file `url` over HTTP and save to `file_name`\n",
      "groud trugh:\t u = urllib.request.urlopen(url)\n",
      "f = open(file_name, 'wb')\n",
      "meta = u.info()\n",
      "file_size = int(meta.getheaders('Content-Length')[0])\n",
      "print(('Downloading: %s Bytes: %s' % (file_name, file_size)))\n",
      "file_size_dl = 0\n",
      "block_sz = 8192\n",
      "while True:\n",
      "    buffer = u.read(block_sz)\n",
      "    if (not buffer):\n",
      "        break\n",
      "    file_size_dl += len(buffer)\n",
      "    f.write(buffer)\n",
      "    status = ('%10d  [%3.2f%%]' % (file_size_dl, ((file_size_dl * 100.0) / file_size)))\n",
      "    status = (status + (chr(8) * (len(status) + 1)))\n",
      "    print(status, end=' ')\n",
      "f.close()\n",
      "prediction: \t with open ( url , file_name ) . read ( ) : \n",
      "      pass \n",
      "\n",
      "intent:     \t download a file 'http://www.example.com/' over HTTP\n",
      "groud trugh:\t response = urllib.request.urlopen('http://www.example.com/')\n",
      "html = response.read()\n",
      "prediction: \t exec ( compile ( open ( 'http://www.example.com/' ) . read ( ) , 'http://www.example.com/' , 'exec' ) )\n",
      "\n",
      "intent:     \t download a file `url` over HTTP\n",
      "groud trugh:\t r = requests.get(url)\n",
      "prediction: \t Image . open ( 'url' )\n",
      "\n",
      "intent:     \t download a file `url` over HTTP and save to \"10MB\"\n",
      "groud trugh:\t response = requests.get(url, stream=True)\n",
      "with open('10MB', 'wb') as handle:\n",
      "    for data in tqdm(response.iter_content()):\n",
      "        handle.write(data)\n",
      "prediction: \t url = open ( '10MB' ) \n",
      " . . show ( ) : \n",
      "      url . write ( ) : \n",
      "      pass \n",
      "\n",
      "intent:     \t argparse add argument with flag '--version' and version action of '%(prog)s 2.0' to parser `parser`\n",
      "groud trugh:\t parser.add_argument('--version', action='version', version='%(prog)s 2.0')\n",
      "prediction: \t subprocess . call ( [ '%(prog)s 2.0' , '--version' , parser ] )\n",
      "\n",
      "intent:     \t remove key 'c' from dictionary `d`\n",
      "groud trugh:\t {i: d[i] for i in d if i != 'c'}\n",
      "prediction: \t { k : d . get ( 'c' ) for k in d . items ( ) }\n",
      "\n",
      "intent:     \t Create new DataFrame object by merging columns \"key\" of  dataframes `split_df` and `csv_df` and rename the columns from dataframes `split_df` and `csv_df` with suffix `_left` and `_right` respectively\n",
      "groud trugh:\t pd.merge(split_df, csv_df, on=['key'], suffixes=('_left', '_right'))\n",
      "prediction: \t pd . merge ( [ 'split_df' , 'csv_df' ] , size = int_0 )\n",
      "\n",
      "intent:     \t Split a string `s` by space with `4` splits\n",
      "groud trugh:\t s.split(' ', 4)\n",
      "prediction: \t [ item . strip ( ) for s in re . split ( '(4)' , s ) ]\n",
      "\n",
      "intent:     \t read keyboard-input\n",
      "groud trugh:\t input('Enter your input:')\n",
      "prediction: \t sys . stdin ( )\n",
      "\n",
      "intent:     \t enable debug mode on Flask application `app`\n",
      "groud trugh:\t app.run(debug=True)\n",
      "prediction: \t app . run ( )\n",
      "\n",
      "intent:     \t python save list `mylist` to file object 'save.txt'\n",
      "groud trugh:\t pickle.dump(mylist, open('save.txt', 'wb'))\n",
      "prediction: \t mylist . write ( 'save.txt' )\n",
      "\n",
      "intent:     \t Multiply a matrix `P` with a 3d tensor `T` in scipy\n",
      "groud trugh:\t scipy.tensordot(P, T, axes=[1, 1]).swapaxes(0, 1)\n",
      "prediction: \t P . T ( T , var_2 [ : : - 1 ] )\n",
      "\n",
      "intent:     \t Create 3d array of zeroes of size `(3,3,3)`\n",
      "groud trugh:\t numpy.zeros((3, 3, 3))\n",
      "prediction: \t np . array ( x , ( (3,3,3) , 3 ) ) . all ( ) [ 1 ]\n",
      "\n",
      "intent:     \t cut off the last word of a sentence `content`\n",
      "groud trugh:\t \"\"\" \"\"\".join(content.split(' ')[:-1])\n",
      "prediction: \t content . split ( ) [ 1 ]\n",
      "\n",
      "intent:     \t convert scalar `x` to array\n",
      "groud trugh:\t x = np.asarray(x).reshape(1, -1)[(0), :]\n",
      "prediction: \t np . array ( np . array ( x , - 1 ) ) . reshape ( 3 )\n",
      "\n",
      "intent:     \t sum all elements of nested list `L`\n",
      "groud trugh:\t sum(sum(i) if isinstance(i, list) else i for i in L)\n",
      "prediction: \t map ( sum , zip ( * L ) )\n",
      "\n",
      "intent:     \t convert hex string '470FC614' to a float number\n",
      "groud trugh:\t struct.unpack('!f', '470FC614'.decode('hex'))[0]\n",
      "prediction: \t int ( '470FC614' . pack ( 'hex' , 16 ) )\n",
      "\n",
      "intent:     \t Multiple each value by `2` for all keys in a dictionary `my_dict`\n",
      "groud trugh:\t my_dict.update((x, y * 2) for x, y in list(my_dict.items()))\n",
      "prediction: \t dict ( ( k , '2' ) for k , v in my_dict . items ( ) )\n",
      "\n",
      "intent:     \t running bash script 'sleep.sh'\n",
      "groud trugh:\t subprocess.call('sleep.sh', shell=True)\n",
      "prediction: \t subprocess . call ( 'sleep.sh' , shell = True )\n",
      "\n",
      "intent:     \t Join elements of list `l` with a comma `,`\n",
      "groud trugh:\t \"\"\",\"\"\".join(l)\n",
      "prediction: \t l [ ',' ] = [ , ]\n",
      "\n",
      "intent:     \t make a comma-separated string from a list `myList`\n",
      "groud trugh:\t myList = ','.join(map(str, myList))\n",
      "prediction: \t myList = list ( myList )\n",
      "\n",
      "intent:     \t reverse the list that contains 1 to 10\n",
      "groud trugh:\t list(reversed(list(range(10))))\n",
      "prediction: \t [ i for i in range ( 10 ) if i > 10 ]\n",
      "\n",
      "intent:     \t remove substring 'bag,' from a string 'lamp, bag, mirror'\n",
      "groud trugh:\t print('lamp, bag, mirror'.replace('bag,', ''))\n",
      "prediction: \t re . sub ( 'lamp, bag, mirror' , '' , 'lamp, bag, mirror' )\n",
      "\n",
      "intent:     \t Reverse the order of words, delimited by `.`, in string `s`\n",
      "groud trugh:\t \"\"\".\"\"\".join(s.split('.')[::-1])\n",
      "prediction: \t re . sub ( '.' , '\\\\1' , s )\n",
      "\n",
      "intent:     \t convert epoch time represented as milliseconds `s` to string using format '%Y-%m-%d %H:%M:%S.%f'\n",
      "groud trugh:\t datetime.datetime.fromtimestamp(s).strftime('%Y-%m-%d %H:%M:%S.%f')\n",
      "prediction: \t hex ( datetime . datetime . strptime ( s , '%Y-%m-%d %H:%M:%S.%f' ) . strftime ( ) )\n",
      "\n",
      "intent:     \t parse milliseconds epoch time '1236472051807' to format '%Y-%m-%d %H:%M:%S'\n",
      "groud trugh:\t time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime(1236472051807 / 1000.0))\n",
      "prediction: \t print ( datetime . datetime . strptime ( '1236472051807' , '%Y-%m-%d %H:%M:%S' ) . strftime ( '%Y-%m-%d %H:%M:%S' ) )\n",
      "\n",
      "intent:     \t get the date 7 days before the current date\n",
      "groud trugh:\t (datetime.datetime.now() - datetime.timedelta(days=7)).date()\n",
      "prediction: \t print ( datetime . date . today ( ) + datetime . timedelta ( 6 / 6 / 12 ) )\n",
      "\n",
      "intent:     \t sum elements at index `column` of each list in list `data`\n",
      "groud trugh:\t print(sum(row[column] for row in data))\n",
      "prediction: \t sum ( i * j for i , j in list ( zip ( column , data ) ) )\n",
      "\n",
      "intent:     \t sum columns of a list `array`\n",
      "groud trugh:\t [sum(row[i] for row in array) for i in range(len(array[0]))]\n",
      "prediction: \t sum ( [ sum ( i * i ) for i , j in list ( itertools . combinations ( array , 1 ) ) ] )\n",
      "\n",
      "intent:     \t encode binary string 'your string' to base64 code\n",
      "groud trugh:\t base64.b64encode(bytes('your string', 'utf-8'))\n",
      "prediction: \t print ( 'your string' . encode ( 'your string' ) )\n",
      "\n",
      "intent:     \t combine list of dictionaries `dicts` with the same keys in each list to a single dictionary\n",
      "groud trugh:\t dict((k, [d[k] for d in dicts]) for k in dicts[0])\n",
      "prediction: \t dict ( ( k , v ) for d in dicts for k , v in list ( d . items ( ) ) )\n",
      "\n",
      "intent:     \t Merge a nested dictionary `dicts` into a flat dictionary by concatenating nested values with the same key `k`\n",
      "groud trugh:\t {k: [d[k] for d in dicts] for k in dicts[0]}\n",
      "prediction: \t dict ( ( k , v ) for k , v in dicts . items ( ) )\n",
      "\n",
      "intent:     \t How do I get the url parameter in a Flask view\n",
      "groud trugh:\t request.args['myParam']\n",
      "prediction: \t root . find_elements_by_xpath ( ) , 1 = False )\n",
      "\n",
      "intent:     \t identify duplicate values in list `mylist`\n",
      "groud trugh:\t [k for k, v in list(Counter(mylist).items()) if v > 1]\n",
      "prediction: \t [ dict ( t ) for t in set ( [ tuple ( d . items ( ) ) ] for t in mylist ] ) ]\n",
      "\n",
      "intent:     \t Insert directory 'apps' into directory `__file__`\n",
      "groud trugh:\t sys.path.insert(1, os.path.join(os.path.dirname(__file__), 'apps'))\n",
      "prediction: \t os . path . insert ( os . path . join ( __file__ , 'apps' ) )\n",
      "\n",
      "intent:     \t modify sys.path for python module `subdir`\n",
      "groud trugh:\t sys.path.append(os.path.join(os.path.dirname(__file__), 'subdir'))\n",
      "prediction: \t subprocess . call ( [ 'subdir' , 'subdir' ] )\n",
      "\n",
      "intent:     \t Insert a 'None' value into a SQLite3 table.\n",
      "groud trugh:\t db.execute(\"INSERT INTO present VALUES('test2', ?, 10)\", (None,))\n",
      "prediction: \t subprocess . call ( 'None' , shell = True )\n",
      "\n",
      "intent:     \t flatten list `list_of_menuitems`\n",
      "groud trugh:\t [image for menuitem in list_of_menuitems for image in menuitem]\n",
      "prediction: \t list_of_menuitems = [ i [ 0 ] for i in range ( 0 , len ( list_of_menuitems ) ) ]\n",
      "\n",
      "intent:     \t append elements of a set `b` to a list `a`\n",
      "groud trugh:\t a.extend(b)\n",
      "prediction: \t a = [ item [ 'b' ] for item in a ]\n",
      "\n",
      "intent:     \t Append elements of a set to a list in Python\n",
      "groud trugh:\t a.extend(list(b))\n",
      "prediction: \t [ ( x , y ) for x , y in zip ( tuple ( x . items ( ) ) ] for e in data ) ]\n",
      "\n",
      "intent:     \t write the data of dataframe `df` into text file `np.txt`\n",
      "groud trugh:\t np.savetxt('c:\\\\data\\\\np.txt', df.values, fmt='%d')\n",
      "prediction: \t df . to_csv ( 'np.txt' , False = False )\n",
      "\n",
      "intent:     \t write content of DataFrame `df` into text file 'c:\\\\data\\\\pandas.txt'\n",
      "groud trugh:\t df.to_csv('c:\\\\data\\\\pandas.txt', header=None, index=None, sep=' ', mode='a')\n",
      "prediction: \t df . to_csv ( 'c:\\\\data\\\\pandas.txt' , sep = False )\n",
      "\n",
      "intent:     \t Split a string `x` by last occurrence of character `-`\n",
      "groud trugh:\t print(x.rpartition('-')[0])\n",
      "prediction: \t re . split ( '(-)' , x . split ( '\\t' ) )\n",
      "\n",
      "intent:     \t get the last part of a string before the character '-'\n",
      "groud trugh:\t print(x.rsplit('-', 1)[0])\n",
      "prediction: \t eval ( '-' )\n",
      "\n",
      "intent:     \t upload file using FTP\n",
      "groud trugh:\t ftp.storlines('STOR ' + filename, open(filename, 'r'))\n",
      "prediction: \t plt . format ( open , filename , file )\n",
      "\n",
      "intent:     \t add one to the hidden web element with id 'XYZ' with selenium python script\n",
      "groud trugh:\t browser.execute_script(\"document.getElementById('XYZ').value+='1'\")\n",
      "prediction: \t driver . find_element_by_id ( 'XYZ' ) . click ( )\n",
      "\n",
      "intent:     \t create array containing the maximum value of respective elements of array `[2, 3, 4]` and array `[1, 5, 2]`\n",
      "groud trugh:\t np.maximum([2, 3, 4], [1, 5, 2])\n",
      "prediction: \t np . zeros ( ( [2, 3, 4] , [1, 5, 2] ) , np . array ( [ [2, 3, 4] ] ) , np . array ( [ [2, 3, 4] ] ) )\n",
      "\n",
      "intent:     \t print a list `l` and move first 3 elements to the end of the list\n",
      "groud trugh:\t print(l[3:] + l[:3])\n",
      "prediction: \t print ( [ l [ 0 ] ) for i in range ( 0 , len ( l ) , 3 ) ]\n",
      "\n",
      "intent:     \t loop over files in directory '.'\n",
      "groud trugh:\t for fn in os.listdir('.'):\n",
      "    if os.path.isfile(fn):\n",
      "        pass\n",
      "prediction: \t os . path ( open ( '.' , os . path . realpath ( '.' ) )\n",
      "\n",
      "intent:     \t loop over files in directory `source`\n",
      "groud trugh:\t for (root, dirs, filenames) in os.walk(source):\n",
      "    for f in filenames:\n",
      "        pass\n",
      "prediction: \t os . os . open ( os . path . realpath ( source ) , os = None )\n",
      "\n",
      "intent:     \t create a random list of integers\n",
      "groud trugh:\t [int(1000 * random.random()) for i in range(10000)]\n",
      "prediction: \t list = random . array ( list ( range ( 9 ) ) , 10 )\n",
      "\n",
      "intent:     \t Using %f with strftime() in Python to get microseconds\n",
      "groud trugh:\t datetime.datetime.now().strftime('%H:%M:%S.%f')\n",
      "prediction: \t datetime . datetime . now ( ) - datetime . timedelta ( days = 1 )\n",
      "\n",
      "intent:     \t Google App Engine execute GQL query 'SELECT * FROM Schedule WHERE station = $1' with parameter `foo.key()`\n",
      "groud trugh:\t db.GqlQuery('SELECT * FROM Schedule WHERE station = $1', foo.key())\n",
      "prediction: \t logging . execute ( 'SELECT * FROM Schedule WHERE station = $1' , ( foo.key() ) )\n",
      "\n",
      "intent:     \t filter rows in pandas starting with alphabet 'f' using regular expression.\n",
      "groud trugh:\t df.b.str.contains('^f')\n",
      "prediction: \t print ( df . loc [ : , ( [ 'str_1' , str_1 ] ) )\n",
      "\n",
      "intent:     \t print a 2 dimensional list `tab` as a table with delimiters\n",
      "groud trugh:\t print('\\n'.join('\\t'.join(str(col) for col in row) for row in tab))\n",
      "prediction: \t self . format ( '\\n' . join ( tab ) )\n",
      "\n",
      "intent:     \t pandas: delete rows in dataframe `df` based on multiple columns values\n",
      "groud trugh:\t df.set_index(list('BC')).drop(tuples, errors='ignore').reset_index()\n",
      "prediction: \t df . groupby ( df . index [ : , ( df . columns [ 0 ] ) ] , axis = 0 )\n",
      "\n",
      "intent:     \t format the variables `self.goals` and `self.penalties` using string formatting\n",
      "groud trugh:\t \"\"\"({:d} goals, ${:d})\"\"\".format(self.goals, self.penalties)\n",
      "prediction: \t \"\"\"self.goals\"\"\" . format ( 'self.goals' , 'self.penalties' )\n",
      "\n",
      "intent:     \t format string \"({} goals, ${})\" with variables `goals` and `penalties`\n",
      "groud trugh:\t \"\"\"({} goals, ${})\"\"\".format(self.goals, self.penalties)\n",
      "prediction: \t \"\"\"({} goals, ${})\"\"\" . format ( goals , penalties )\n",
      "\n",
      "intent:     \t format string \"({0.goals} goals, ${0.penalties})\"\n",
      "groud trugh:\t \"\"\"({0.goals} goals, ${0.penalties})\"\"\".format(self)\n",
      "prediction: \t \"\"\"({0.goals} goals, ${0.penalties})\"\"\" . format ( '({0.goals} goals, ${0.penalties})' )\n",
      "\n",
      "intent:     \t convert list of lists `L` to list of integers\n",
      "groud trugh:\t [int(''.join(str(d) for d in x)) for x in L]\n",
      "prediction: \t [ map ( int , sublist ) for sublist in L ]\n",
      "\n",
      "intent:     \t combine elements of each list in list `L` into digits of a single integer\n",
      "groud trugh:\t [''.join(str(d) for d in x) for x in L]\n",
      "prediction: \t map ( '' . join , zip ( * L ) )\n",
      "\n",
      "intent:     \t convert a list of lists `L` to list of integers\n",
      "groud trugh:\t L = [int(''.join([str(y) for y in x])) for x in L]\n",
      "prediction: \t [ map ( int , sublist ) for sublist in L ]\n",
      "\n",
      "intent:     \t write the elements of list `lines` concatenated by special character '\\n' to file `myfile`\n",
      "groud trugh:\t myfile.write('\\n'.join(lines))\n",
      "prediction: \t lines . split ( myfile , * ( '\\n' , 1 ) )\n",
      "\n",
      "intent:     \t removing an element from a list based on a predicate 'X' or 'N'\n",
      "groud trugh:\t [x for x in ['AAT', 'XAC', 'ANT', 'TTA'] if 'X' not in x and 'N' not in x]\n",
      "prediction: \t [ k for k , v in itertools . groupby ( N ) if item . startswith ( ) [ 'bar' ] ]\n",
      "\n",
      "intent:     \t Remove duplicate words from a string `text` using regex\n",
      "groud trugh:\t text = re.sub('\\\\b(\\\\w+)( \\\\1\\\\b)+', '\\\\1', text)\n",
      "prediction: \t re . sub ( , , '\\\\1' , text )\n",
      "\n",
      "intent:     \t count non zero values in each column in pandas data frame\n",
      "groud trugh:\t df.astype(bool).sum(axis=1)\n",
      "prediction: \t df . groupby ( df . apply ( lambda x : x . isnull ( ) , axis = 1 ) . sum ( )\n",
      "\n",
      "intent:     \t search for string that matches regular expression pattern '(?<!Distillr)\\\\\\\\AcroTray\\\\.exe' in string 'C:\\\\SomeDir\\\\AcroTray.exe'\n",
      "groud trugh:\t re.search('(?<!Distillr)\\\\\\\\AcroTray\\\\.exe', 'C:\\\\SomeDir\\\\AcroTray.exe')\n",
      "prediction: \t re . compile ( 'C:\\\\SomeDir\\\\AcroTray.exe' , '(?<!Distillr)\\\\\\\\AcroTray\\\\.exe' )\n",
      "\n",
      "intent:     \t split string 'QH QD JC KD JS' into a list on white spaces\n",
      "groud trugh:\t \"\"\"QH QD JC KD JS\"\"\".split()\n",
      "prediction: \t \"\"\"QH QD JC KD JS\"\"\" . join ( x ) for x in re . split ( 'QH QD JC KD JS' , 'QH QD JC KD JS' ) )\n",
      "\n",
      "intent:     \t search for occurrences of regex pattern '>.*<' in xml string `line`\n",
      "groud trugh:\t print(re.search('>.*<', line).group(0))\n",
      "prediction: \t re . search ( '(>.*<)' , line , re . IGNORECASE )\n",
      "\n",
      "intent:     \t erase all the contents of a file `filename`\n",
      "groud trugh:\t open(filename, 'w').close()\n",
      "prediction: \t open ( 'filename' , 'w' ) . close ( )\n",
      "\n",
      "intent:     \t convert a string into datetime using the format '%Y-%m-%d %H:%M:%S.%f'\n",
      "groud trugh:\t datetime.datetime.strptime(string_date, '%Y-%m-%d %H:%M:%S.%f')\n",
      "prediction: \t datetime . datetime . strptime ( '%Y-%m-%d %H:%M:%S.%f' , '%Y-%m-%d %H:%M:%S.%f' ) . time ( )\n",
      "\n",
      "intent:     \t find the index of a list with the first element equal to '332' within the list of lists `thelist`\n",
      "groud trugh:\t [index for index, item in enumerate(thelist) if item[0] == '332']\n",
      "prediction: \t [ x [ 0 ] for x in thelist if x [ '332' ] ]\n",
      "\n",
      "intent:     \t lower a string `text` and remove non-alphanumeric characters aside from space\n",
      "groud trugh:\t re.sub('[^\\\\sa-zA-Z0-9]', '', text).lower().strip()\n",
      "prediction: \t re . sub ( '\\\\' , '' , text )\n",
      "\n",
      "intent:     \t remove all non-alphanumeric characters except space from a string `text` and lower it\n",
      "groud trugh:\t re.sub('(?!\\\\s)[\\\\W_]', '', text).lower().strip()\n",
      "prediction: \t re . sub ( '\\\\' , '' , text )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    print('intent:     \\t', intent)\n",
    "    print('groud trugh:\\t', code)\n",
    "    print('prediction: \\t', pmi_code_list[i])\n",
    "    print()\n",
    "    \n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intent:      \t convert hex string '470FC614' to a float number\n",
      "ground truth:\t struct.unpack('!f', '470FC614'.decode('hex'))[0]\n",
      "before rerank:\n",
      "Model score:-0.33\tBLEU score:0.31:\tstruct . unpack ( 'd' , struct . pack ( 'hex' , 16 ) )\n",
      "Model score:-0.30\tBLEU score:0.08:\thex ( int ( '470FC614' , 16 ) )\n",
      "Model score:-0.28\tBLEU score:0.08:\tint ( int ( '470FC614' , 16 ) )\n",
      "Model score:-0.26\tBLEU score:0.08:\tint ( ord ( '470FC614' , 16 ) )\n",
      "Model score:-0.15\tBLEU score:0.04:\tint ( '470FC614' , 16 )\n",
      "\n",
      "after rerank:\n",
      "Rerank score:1.14\tBLEU score:0.08:\tint ( int ( '470FC614' , 16 ) )\n",
      "Rerank score:1.33\tBLEU score:0.04:\tint ( '470FC614' , 16 )\n",
      "Rerank score:1.42\tBLEU score:0.08:\tint ( ord ( '470FC614' , 16 ) )\n",
      "Rerank score:1.59\tBLEU score:0.08:\thex ( int ( '470FC614' , 16 ) )\n",
      "Rerank score:2.01\tBLEU score:0.31:\tstruct . unpack ( 'd' , struct . pack ( 'hex' , 16 ) )\n"
     ]
    }
   ],
   "source": [
    "from decoder import post_process_test\n",
    "\n",
    "src_seq, slot_map, code, intent = testloader[43]\n",
    "\n",
    "beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=5)\n",
    "post_process_test(intent, beams, idx2code, intent2idx, pmi, process_intent, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerank with Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rerank_model import ScoreNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## encoder architecture\n",
    "    'encoder_layers': 2,\n",
    "    'encoder_embed_size': 128,\n",
    "    'encoder_hidden_size': 256,\n",
    "    'encoder_dropout_rate': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_net = ScoreNet(word_size, code_size, hyperP).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_net.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import process_intent\n",
    "\n",
    "model_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, _, code, intent) in enumerate(testloader):\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=20)\n",
    "    model_code =  post_process_model(intent, beams, idx2code, score_net, process_intent, intent2idx)\n",
    "    model_code_list.append(model_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3189677547378042"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(pmi_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Hand Featured Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import write_answer_json\n",
    "write_answer_json(pmi_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: answer.txt (deflated 72%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip answer.zip answer.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
