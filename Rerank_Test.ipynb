{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./preprocessing')\n",
    "sys.path.append('./seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import Code_Intent_Pairs\n",
    "from model import Seq2Seq\n",
    "from data import get_test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_intent_pair = Code_Intent_Pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'vocab/'\n",
    "code_intent_pair.load_dict(path)\n",
    "special_symbols = code_intent_pair.get_special_symbols()\n",
    "word_size = code_intent_pair.get_word_size()\n",
    "code_size = code_intent_pair.get_code_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'processed_corpus/test.json'\n",
    "test_entries = code_intent_pair.load_entries(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = get_test_loader(test_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## training parameters\n",
    "    'batch_size' : 32,\n",
    "    'lr' : 1e-3,\n",
    "    'teacher_force_rate' : 0.90,\n",
    "    'max_epochs' : 50,\n",
    "    'lr_keep_rate' : 0.95,  # set to 1.0 to not decrease lr overtime\n",
    "    'load_pretrain_code_embed': False,\n",
    "    'freeze_embed': False,\n",
    "    \n",
    "    ## encoder architecture\n",
    "    'encoder_layers' : 2,\n",
    "    'encoder_embed_size' : 128,\n",
    "    'encoder_hidden_size' : 384,\n",
    "    'encoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## decoder architecture\n",
    "    'decoder_layers' : 2,\n",
    "    'decoder_embed_size' : 128,\n",
    "    'decoder_hidden_size' : 384,\n",
    "    'decoder_dropout_rate' : 0.3,\n",
    "    \n",
    "    ## attn architecture\n",
    "    'attn_hidden_size' : 384,\n",
    "    \n",
    "    ## visualization\n",
    "    'print_every': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(word_size, code_size, hyperP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if hyperP['load_pretrain_code_embed']:\n",
    "    model.decoder.embed[0].load_state_dict(torch.load('./pretrain_code_lm/embedding-1556211835.t7'))\n",
    "    if hyperP['freeze_embed']:\n",
    "        for param in model.decoder.embed[0].parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder import Decoder\n",
    "from decoder import post_process_test, post_process_hand\n",
    "from decoder import post_process_dummy, post_process_model\n",
    "from evaluate import get_bleu_all, get_bleu_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_decoder = Decoder(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sos = special_symbols['code_sos']\n",
    "eos = special_symbols['code_eos']\n",
    "unk = special_symbols['code_unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2code = code_intent_pair.idx2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent2idx = code_intent_pair.intent2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=3)\n",
    "    dummy_code =  post_process_dummy(slot_map, beams, idx2code)\n",
    "    dummy_code_list.append(dummy_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2642075877054355"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(dummy_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerank with Hand Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, slot_map, code, intent) in enumerate(testloader):\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=20)\n",
    "    hand_code =  post_process_hand(intent, slot_map, beams, idx2code)\n",
    "    hand_code_list.append(hand_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bleu_all(hand_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Hnad Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining data from dataframe `df1` with data from dataframe `df2` based on matching values of column 'Date_Time' in both dataframes\n",
      "df1.merge(df2, on='Date_Time')\n",
      "{'var_0': 'df1', 'var_1': 'df2', 'str_0': 'Date_Time'}\n",
      "before process:\n",
      "b_score:-0.34\tscore:0.31:\tpd . merge ( df1 , df2 , how = 'Date_Time' , on = 'str_1' )\n",
      "b_score:-0.33\tscore:0.10:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( )\n",
      "b_score:-0.32\tscore:0.28:\tdf1 . loc ( index = 'Date_Time' , columns = 'Date_Time' )\n",
      "b_score:-0.32\tscore:0.08:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( ) . reset_index ( )\n",
      "b_score:-0.31\tscore:0.39:\tpd . merge ( df1 , df2 , how = 'Date_Time' , on = 'Date_Time' )\n",
      "b_score:-0.31\tscore:0.19:\tpd . merge ( df1 , df2 , how = [ 'Date_Time' ] )\n",
      "b_score:-0.31\tscore:0.11:\tpd . concat ( [ df1 , df2 ] , axis = [ 'Date_Time' ] )\n",
      "b_score:-0.30\tscore:0.22:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( ) = 'Date_Time' )\n",
      "b_score:-0.29\tscore:0.27:\tpd . concat ( [ df1 , df2 ] , axis = 'Date_Time' )\n",
      "b_score:-0.23\tscore:0.13:\tdf1 . loc [ df1 [ 'Date_Time' ] . isin ( ) ]\n",
      "\n",
      "after process:\n",
      "b_score:-0.56\tscore:0.31:\tpd . merge ( df1 , df2 , how = 'Date_Time' , on = 'str_1' )\n",
      "b_score:0.18\tscore:0.10:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( )\n",
      "b_score:0.20\tscore:0.08:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( ) . reset_index ( )\n",
      "b_score:0.37\tscore:0.19:\tpd . merge ( df1 , df2 , how = [ 'Date_Time' ] )\n",
      "b_score:0.38\tscore:0.13:\tdf1 . loc [ df1 [ 'Date_Time' ] . isin ( ) ]\n",
      "b_score:0.42\tscore:0.28:\tdf1 . loc ( index = 'Date_Time' , columns = 'Date_Time' )\n",
      "b_score:0.46\tscore:0.39:\tpd . merge ( df1 , df2 , how = 'Date_Time' , on = 'Date_Time' )\n",
      "b_score:0.51\tscore:0.22:\tpd . concat ( [ df1 , df2 ] ) . merge ( ) . reset_index ( ) = 'Date_Time' )\n",
      "b_score:0.53\tscore:0.11:\tpd . concat ( [ df1 , df2 ] , axis = [ 'Date_Time' ] )\n",
      "b_score:0.55\tscore:0.27:\tpd . concat ( [ df1 , df2 ] , axis = 'Date_Time' )\n"
     ]
    }
   ],
   "source": [
    "src_seq, slot_map, code, intent = testloader[107]\n",
    "beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=10)\n",
    "post_process_test(intent, slot_map, beams, idx2code, code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.wordnet.WordNetLemmatizer()\n",
    "lemmatizer.lemmatize('running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerank with Neural Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rerank_model import ScoreNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperP = {\n",
    "    ## encoder architecture\n",
    "    'encoder_layers': 2,\n",
    "    'encoder_embed_size': 128,\n",
    "    'encoder_hidden_size': 256,\n",
    "    'encoder_dropout_rate': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_net = ScoreNet(word_size, code_size, hyperP).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_net.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor import process_intent\n",
    "\n",
    "model_code_list = []\n",
    "true_code_list = []\n",
    "\n",
    "for i, (src_seq, _, code, intent) in enumerate(testloader):\n",
    "    beams = beam_decoder.decode(src_seq, sos, eos, unk, beam_width=20)\n",
    "    model_code =  post_process_model(intent, beams, idx2code, score_net, process_intent, intent2idx)\n",
    "    model_code_list.append(model_code)\n",
    "    true_code_list.append(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.301039007821032"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu_all(hand_code_list, true_code_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Hand Featured Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import write_answer_json\n",
    "write_answer_json(hand_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: word unexpected (expecting \")\")\r\n"
     ]
    }
   ],
   "source": [
    "!zip('answer.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
