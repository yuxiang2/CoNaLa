{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import preprocess_temp as P\n",
    "import model.parsers as M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './conala-corpus/'\n",
    "train_file = directory + 'train.json'\n",
    "test_file = directory + 'test.json'\n",
    "\n",
    "with open(train_file) as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(test_file) as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's preprocess the data. Everything is in Preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent processing includes lowercase, remove punctuation'?'\n",
    "train_intent, train_codes = P.process_data(train_data)\n",
    "test_intent, test_codes = P.process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class is used for code2actions and actions2code\n",
    "ast_action = P.Ast_Action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actions = []\n",
    "\n",
    "for code in train_codes:\n",
    "    train_actions.append(ast_action.code2actions(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_lst = P.vocab_list(train_intent, cut_freq=5)\n",
    "act_lst, token_lst = P.action_list(train_actions, cut_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2num = dict(zip(word_lst, range(0,len(word_lst))))\n",
    "act2num = dict(zip(act_lst, range(0,len(act_lst))))\n",
    "token2num = dict(zip(token_lst, range(0,len(token_lst))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = P.get_train_loader(train_intent, train_actions, word2num, act2num, token2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = P.get_test_loader(test_intent, word2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_index_copy = act2num[P.GenTokenAction('copy')]\n",
    "action_index_gen = act2num[P.GenTokenAction('token')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "hyperParamMap = {\n",
    "    #### General configuration ####\n",
    "    'cuda': True,      # Use gpu\n",
    "    'asdl_file': '',   # Path to ASDL grammar specification\n",
    "    'mode': 'train',   # train or test\n",
    "\n",
    "    #### Modularized configuration ####\n",
    "    'parser': 'default_parser',  # which parser model to use\n",
    "\n",
    "    #### Model configuration ####\n",
    "    'lstm': 'lstm',    # Type of LSTM used, currently only standard LSTM cell is supported\n",
    "\n",
    "    #### Embedding sizes ####\n",
    "    'embed_size': 128,         # Size of word embeddings\n",
    "    'action_embed_size': 128,  # Size of ApplyRule/GenToken action embeddings\n",
    "    'field_embed_size': 64,    # Embedding size of ASDL fields\n",
    "    'type_embed_size': 64,     # Embeddings ASDL types\n",
    "\n",
    "    #### Hidden sizes ####\n",
    "    'hidden_size': 256,        # Size of LSTM hidden states\n",
    "    'ptrnet_hidden_dim': 32,   # Hidden dimension used in pointer network\n",
    "    'att_vec_size': 256,       # Size of attentional vector\n",
    "\n",
    "    #### readout layer ####\n",
    "    'no_query_vec_to_action_map': False,    # Do not use additional linear layer to transform the attentional vector for computing action probabilities\n",
    "    'readout': 'identity',                  # Type of activation if using additional linear layer\n",
    "    'query_vec_to_action_diff_map': False,  # Use different linear mapping \n",
    "\n",
    "    #### parent information switch for decoder LSTM ####\n",
    "    'no_parent_production_embed': False,    # Do not use embedding of parent ASDL production to update decoder LSTM state\n",
    "    'no_parent_field_embed': False,         # Do not use embedding of parent field to update decoder LSTM state\n",
    "    'no_parent_field_type_embed': False,    # Do not use embedding of the ASDL type of parent field to update decoder LSTM state\n",
    "    'no_parent_state': True,                # Do not use the parent hidden state to update decoder LSTM state\n",
    "    'no_input_feed': False,                 # Do not use input feeding in decoder LSTM\n",
    "    'no_copy': False,                       # Do not use copy mechanism\n",
    "\n",
    "    #### Training ####\n",
    "    'vocab': '',                            # Path of the serialized vocabulary\n",
    "    'train_file': '',                       # path to the training target file\n",
    "    'dev_file': '',                         # path to the dev source file\n",
    "    'batch_size': 10,                       # Batch size\n",
    "    'dropout': 0.,                          # dropout rate\n",
    "    'word_dropout': 0.,                     # Word dropout rate\n",
    "    'decoder_word_dropout': 0.,             # Word dropout rate on decoder\n",
    "    'primitive_token_label_smoothing': 0.0, # Apply label smoothing when predicting primitive tokens\n",
    "    'src_token_label_smoothing': 0.0,       # Apply label smoothing in reconstruction model when predicting source tokens\n",
    "    'negative_sample_type': 'best',         # \n",
    "\n",
    "    #### training schedule details ####\n",
    "    'valid_metric': 'acc',                # Metric used for validation\n",
    "    'valid_every_epoch': 1,               # Perform validation every x epoch\n",
    "    'log_every': 10,                      # Log training statistics every n iterations\n",
    "    'save_to': 'model',                   # Save trained model to\n",
    "    'save_all_models': False,             # Save all intermediate checkpoints\n",
    "    'patience': 5,                        # Training patience\n",
    "    'max_num_trial': 10,                  # Stop training after x number of trials\n",
    "    'glorot_init': False,                 # Use glorot initialization\n",
    "    'clip_grad': 5.,                      # Clip gradients\n",
    "    'max_epoch': 10,                      # Maximum number of training epoches\n",
    "    'optimizer': 'Adam',                  # optimizer\n",
    "    'lr': 0.001,                          # Learning rate\n",
    "    'lr_decay': 0.5,                      # decay learning rate if the validation performance drops\n",
    "    'lr_decay_after_epoch': 0,            # Decay learning rate after x epoch\n",
    "    'decay_lr_every_epoch': False,        # force to decay learning rate after each epoch\n",
    "    'reset_optimizer': False,             # Whether to reset optimizer when loading the best checkpoint\n",
    "    'verbose': False,                     # Verbose mode\n",
    "\n",
    "    #### decoding/validation/testing ####\n",
    "    'load_model': None,                   # Load a pre-trained model\n",
    "    'beam_size': 5,                       # Beam size for beam search\n",
    "    'decode_max_time_step': 100,          # Maximum number of time steps used in decoding and sampling\n",
    "    'sample_size': 5,                     # Sample size\n",
    "    'test_file': '',                      # Path to the test file\n",
    "    'save_decode_to': None,               # Save decoding results to file\n",
    "}\n",
    "\n",
    "HyperParams = namedtuple('HyperParams', list(hyperParamMap.keys()), verbose=False)\n",
    "hyperParams = HyperParams(**hyperParamMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M.Model(hyperParams, action_size=len(act_lst), token_size=len(token_lst), word_size=len(word_lst), \n",
    "                      action_index_copy=action_index_copy, action_index_gen=action_index_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inp = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model(sample_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
